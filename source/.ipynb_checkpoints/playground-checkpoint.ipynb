{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground\n",
    "\n",
    "This file is for testing and trying out stuff. I'm going to put the pipeline later into simple .py files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import io\n",
    "from scipy import ndimage\n",
    "from PIL import Image as Img\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and merging files\n",
      "/home/beni/Documents/BachelorArbeit/bachelors-thesis-bkrumme/source/../data/huiying_labeled/huiying_part1.mat\n",
      "Data ready\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading and merging files\")\n",
    "data = load_data()\n",
    "print(\"Data ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing the dataset\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shape</th>\n",
       "      <th>size</th>\n",
       "      <th>img_abs</th>\n",
       "      <th>img_ang</th>\n",
       "      <th>label_habit</th>\n",
       "      <th>label_proc_pristine</th>\n",
       "      <th>label_proc_aggregate</th>\n",
       "      <th>label_proc_rimed</th>\n",
       "      <th>label_proc_aged</th>\n",
       "      <th>label_proc_frozen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-11-11-15-50-03-120775_+0.74_+2.41_+36.00_+343.7</th>\n",
       "      <td>(146, 112)</td>\n",
       "      <td>146</td>\n",
       "      <td>[[1.29207e-40, 3.230577e-36, 7.463587e-35, 4.9...</td>\n",
       "      <td>[[4.68157e-40, 2.6673643e-36, 6.1370224e-35, 4...</td>\n",
       "      <td>Column</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-11-15-50-08-635363_-4.28_+1.28_+69.80_+827.2</th>\n",
       "      <td>(282, 330)</td>\n",
       "      <td>330</td>\n",
       "      <td>[[-0.0, -0.0, 0.0, -0.0, 0.0, -3.5e-44, 9.5734...</td>\n",
       "      <td>[[0.0, 0.0, -0.0, 0.0, -0.0, -3.8e-44, -8.2e-4...</td>\n",
       "      <td>Irregular</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         shape  size  \\\n",
       "2019-11-11-15-50-03-120775_+0.74_+2.41_+36.00_+...  (146, 112)   146   \n",
       "2019-11-11-15-50-08-635363_-4.28_+1.28_+69.80_+...  (282, 330)   330   \n",
       "\n",
       "                                                                                              img_abs  \\\n",
       "2019-11-11-15-50-03-120775_+0.74_+2.41_+36.00_+...  [[1.29207e-40, 3.230577e-36, 7.463587e-35, 4.9...   \n",
       "2019-11-11-15-50-08-635363_-4.28_+1.28_+69.80_+...  [[-0.0, -0.0, 0.0, -0.0, 0.0, -3.5e-44, 9.5734...   \n",
       "\n",
       "                                                                                              img_ang  \\\n",
       "2019-11-11-15-50-03-120775_+0.74_+2.41_+36.00_+...  [[4.68157e-40, 2.6673643e-36, 6.1370224e-35, 4...   \n",
       "2019-11-11-15-50-08-635363_-4.28_+1.28_+69.80_+...  [[0.0, 0.0, -0.0, 0.0, -0.0, -3.8e-44, -8.2e-4...   \n",
       "\n",
       "                                                   label_habit  \\\n",
       "2019-11-11-15-50-03-120775_+0.74_+2.41_+36.00_+...      Column   \n",
       "2019-11-11-15-50-08-635363_-4.28_+1.28_+69.80_+...   Irregular   \n",
       "\n",
       "                                                    label_proc_pristine  \\\n",
       "2019-11-11-15-50-03-120775_+0.74_+2.41_+36.00_+...                    0   \n",
       "2019-11-11-15-50-08-635363_-4.28_+1.28_+69.80_+...                    0   \n",
       "\n",
       "                                                    label_proc_aggregate  \\\n",
       "2019-11-11-15-50-03-120775_+0.74_+2.41_+36.00_+...                     0   \n",
       "2019-11-11-15-50-08-635363_-4.28_+1.28_+69.80_+...                     0   \n",
       "\n",
       "                                                    label_proc_rimed  \\\n",
       "2019-11-11-15-50-03-120775_+0.74_+2.41_+36.00_+...                 0   \n",
       "2019-11-11-15-50-08-635363_-4.28_+1.28_+69.80_+...                 0   \n",
       "\n",
       "                                                    label_proc_aged  \\\n",
       "2019-11-11-15-50-03-120775_+0.74_+2.41_+36.00_+...                1   \n",
       "2019-11-11-15-50-08-635363_-4.28_+1.28_+69.80_+...                1   \n",
       "\n",
       "                                                    label_proc_frozen  \n",
       "2019-11-11-15-50-03-120775_+0.74_+2.41_+36.00_+...                  0  \n",
       "2019-11-11-15-50-08-635363_-4.28_+1.28_+69.80_+...                  0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Preprocessing the dataset\")\n",
    "img_size = 64\n",
    "data[\"shape\"] = data[\"img\"].map(lambda img: img.shape)\n",
    "data[\"size\"] = data[\"shape\"].map(lambda shape: max(shape))\n",
    "data[\"img_abs\"] = data[\"img\"].map(lambda img: preprocess_img(np.absolute(img), img_size))\n",
    "data[\"img_ang\"] = data[\"img\"].map(lambda img: preprocess_img(np.angle(img), img_size))\n",
    "data[\"label_habit\"] = data[\"label\"].map(lambda label: label[0])\n",
    "data[\"label_proc_pristine\"] = data[\"label\"].map(lambda label: label[1][0])\n",
    "data[\"label_proc_aggregate\"] = data[\"label\"].map(lambda label: label[1][1])\n",
    "data[\"label_proc_rimed\"] = data[\"label\"].map(lambda label: label[1][2])\n",
    "data[\"label_proc_aged\"] = data[\"label\"].map(lambda label: label[1][3])\n",
    "data[\"label_proc_frozen\"] = data[\"label\"].map(lambda label: label[1][4])\n",
    "data = data.drop(columns=['label', 'img'])\n",
    "\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduces dataframe to only contain a single class (deletes the rest)\n",
    "def return_habit(data, habit):\n",
    "    data = data.drop(data[data.label_habit != habit].index)\n",
    "    return data\n",
    "\n",
    "Columns = return_habit(data, \"Column\")\n",
    "def return_process(data, process):\n",
    "    process_dict = {\n",
    "        \"pristine\" : \"label_proc_pristine\",\n",
    "        \"aggregate\" : \"label_proc_aggregate\",\n",
    "        \"rimed\" : \"label_proc_rimed\",\n",
    "        \"aged\" : \"label_proc_aged\",\n",
    "        \"frozen\" : \"label_proc_frozen\"\n",
    "    }\n",
    "    data = data.drop(data[data[process_dict[process]] != 1].index)\n",
    "    return data\n",
    "\n",
    "# Cols_rimed = return_process(Columns, \"rimed\")\n",
    "\n",
    "Columns.to_pickle(\"../data/pickle/Huiying_part1_columns.pkl\")\n",
    "# save as pkl or as df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  pristine  aggregate  rimed  aged  frozen  total\n",
      "Column                1008        953    385  1342       0   3436\n",
      "Plate                  124         36      0   275       0    400\n",
      "Droplet                  0        332     27    71     546    955\n",
      "Droplet Lollipop       142          0      0     0       0    142\n",
      "Irregular              694         71    138   615       0   1448\n",
      "Rosette                  7          0      0     0       0      7\n",
      "Plate Column            70          0      0     0       0     70\n",
      "Dendrite                 0          0      0     0       0      0\n",
      "Lollipop                 0          0      0     8       0      8\n",
      "Graupel                  1          0      0     0       0      1\n",
      "Branch                   0          0      0     0       0      0\n",
      "Small                  201          0      0     0       0    201\n",
      "Out of focus            17          0      0     0       0     17\n",
      "Recirculation          140          0      0     0       0    140\n",
      "Others                   0          0      0     0       0      0\n",
      "\n",
      "The sum of all physical processes of a habit can be bigger than the total, \n",
      "since an ice crystal can have multiple physical processes.\n"
     ]
    }
   ],
   "source": [
    "def print_matrix(data):\n",
    "    #matrix = np.zeros((5, 14))\n",
    "    feature_list = [\"Column\",\"Plate\",\"Droplet\",\"Droplet Lollipop\",\"Irregular\",\"Rosette\",\"Plate Column\",\n",
    "                    \"Dendrite\",\"Lollipop\",\"Graupel\",\"Branch\",\"Small\",\"Out of focus\",\"Recirculation\",\"Others\"]\n",
    "    physical_processes = [\"pristine\", \"aggregate\", \"rimed\", \"aged\", \"frozen\", \"total\"]\n",
    "    matrix =  pd.DataFrame(0, index=feature_list, columns=physical_processes)\n",
    "    \n",
    "    for i in range(len(data.index)):\n",
    "        habit = data[\"label_habit\"][i]\n",
    "        matrix[\"pristine\"][habit] += data[\"label_proc_pristine\"][i]\n",
    "        matrix[\"aggregate\"][habit] += data[\"label_proc_aggregate\"][i]\n",
    "        matrix[\"rimed\"][habit] += data[\"label_proc_rimed\"][i]\n",
    "        matrix[\"aged\"][habit] += data[\"label_proc_aged\"][i]\n",
    "        matrix[\"frozen\"][habit] += data[\"label_proc_frozen\"][i]\n",
    "        matrix[\"total\"][habit] += 1\n",
    "    print(matrix)\n",
    "    print(\"\\nThe sum of all physical processes of a habit can be bigger than the total, \\nsince an ice crystal can have multiple physical processes.\")\n",
    "    \n",
    "    \n",
    "print_matrix(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b08a1e332b31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_ang\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_ang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mshow_imgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def show_imgs(data, *args):\n",
    "    n = len(args)\n",
    "    if n > 1:\n",
    "        f, ax = plt.subplots(n,2,figsize=(15,25))\n",
    "        for i, idx in enumerate(args):\n",
    "            img_abs = data[\"img_abs\"][idx]\n",
    "            img_ang = data[\"img_ang\"][idx]\n",
    "            ax[i,0].imshow(Img.fromarray(img_abs*255/np.max(img_abs)).convert(\"RGB\"))\n",
    "            ax[i,1].imshow(Img.fromarray(img_ang*255/np.max(img_ang)).convert(\"RGB\"))\n",
    "    else:\n",
    "        f,ax = plt.subplots(1,2,figsize=(15,25))\n",
    "        img_abs = data[\"img_abs\"][args[0]]\n",
    "        img_ang = data[\"img_ang\"][args[0]]\n",
    "        ax[0].imshow(Img.fromarray(img_abs*255/np.max(img_abs)).convert(\"RGB\"))\n",
    "        ax[1].imshow(Img.fromarray(img_ang*255/np.max(img_ang)).convert(\"RGB\"))\n",
    "\n",
    "show_imgs(data,1,2,3,4,5,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Particle Information ###\n",
      "Total number of samples: 7200\n",
      "Ice:\t\t 6825 \t 94.79%\n",
      "Water:\t\t 40 \t 0.56%\n",
      "noIce:\t\t 171 \t 2.38%\n",
      "Artifact:\t 140 \t 1.94%\n",
      "Unsure:\t\t 4 \t 0.06%\n",
      "Unknown:\t 20 \t 0.28%\n",
      "\n",
      "### Habit Information of Ice Particles ###\n",
      "Total number of Ice particles:  6825\n",
      "Column:\t\t 3436 \t 50.34%\n",
      "Plate:\t\t 400 \t 5.86%\n",
      "Droplet:\t 955 \t 13.99%\n",
      "Dropl.Lollipop:\t 142 \t 2.08%\n",
      "Irregular:\t 1448 \t 21.22%\n",
      "Rosette:\t 7 \t 0.1%\n",
      "PlateColumn:\t 70 \t 1.03%\n",
      "Dendrite:\t 0 \t 0.0%\n",
      "Lollipop:\t 8 \t 0.12%\n",
      "Graupel:\t 1 \t 0.01%\n",
      "Branch:\t\t 0 \t 0.0%\n",
      "Small:\t\t 201 \t 2.95%\n",
      "Recirculation:\t 17 \t 0.25%\n",
      "Others:\t\t 140 \t 2.05%\n",
      "\n",
      "### Physical Process Information of Ice Particles ###\n",
      "Pristine:\t 2387 \t 34.97%\n",
      "Aggregate:\t 1392 \t 20.4%\n",
      "Rimed:\t\t 550 \t 8.06%\n",
      "Aged:\t\t 2311 \t 33.86%\n",
      "Frozen:\t\t 546 \t 8.0%\n"
     ]
    }
   ],
   "source": [
    "def print_statistic(data):\n",
    "    num_samples = len(data.index)   \n",
    "    num_particle_ice = len(data[(data['label_particle'] == 0)].index)\n",
    "    num_particle_water = len(data[(data['label_particle'] == 1)].index)\n",
    "    num_particle_noIce = len(data[(data['label_particle'] == 2)].index)\n",
    "    num_particle_artifact = len(data[(data['label_particle'] == 3)].index)\n",
    "    num_particle_unsure = len(data[(data['label_particle'] == 4)].index)\n",
    "    num_particle_unknown = len(data[(data['label_particle'] == 5)].index)\n",
    "    \n",
    "    print(\"### Particle Information ###\")\n",
    "    print(\"Total number of samples:\", num_samples)    \n",
    "    print(\"Ice:\\t\\t\", num_particle_ice, \"\\t\", str(round(num_particle_ice * 100 / num_samples,2))+\"%\")\n",
    "    print(\"Water:\\t\\t\", num_particle_water,\"\\t\", str(round(num_particle_water * 100 / num_samples,2))+\"%\")\n",
    "    print(\"noIce:\\t\\t\", num_particle_noIce,\"\\t\", str(round(num_particle_noIce * 100 / num_samples,2))+\"%\")\n",
    "    print(\"Artifact:\\t\", num_particle_artifact,\"\\t\", str(round(num_particle_artifact * 100 / num_samples,2))+\"%\")\n",
    "    print(\"Unsure:\\t\\t\", num_particle_unsure,\"\\t\", str(round(num_particle_unsure * 100 / num_samples,2))+\"%\")\n",
    "    print(\"Unknown:\\t\", num_particle_unknown,\"\\t\", str(round(num_particle_unknown * 100 / num_samples,2))+\"%\")\n",
    "    print(\"\")\n",
    "    \n",
    "    num_habit_column = len(data[(data['label_habit'] == 0)].index)\n",
    "    num_habit_plate = len(data[(data['label_habit'] == 1)].index)\n",
    "    num_habit_droplet = len(data[(data['label_habit'] == 2)].index)\n",
    "    num_habit_dropletLollipop = len(data[(data['label_habit'] == 3)].index)\n",
    "    num_habit_irregular = len(data[(data['label_habit'] == 4)].index)\n",
    "    num_habit_rosette = len(data[(data['label_habit'] == 5)].index)\n",
    "    num_habit_plateColumn = len(data[(data['label_habit'] == 6)].index)\n",
    "    num_habit_dendrite = len(data[(data['label_habit'] == 7)].index)\n",
    "    num_habit_lollipop = len(data[(data['label_habit'] == 8)].index)\n",
    "    num_habit_graupel = len(data[(data['label_habit'] == 9)].index)\n",
    "    num_habit_branch = len(data[(data['label_habit'] == 10)].index)\n",
    "    num_habit_small = len(data[(data['label_habit'] == 11)].index)\n",
    "    num_habit_recirculation = len(data[(data['label_habit'] == 12)].index)\n",
    "    num_habit_others = len(data[(data['label_habit'] == 13)].index)\n",
    "    \n",
    "    print(\"### Habit Information of Ice Particles ###\")\n",
    "    print(\"Total number of Ice particles: \", num_particle_ice)\n",
    "    print(\"Column:\\t\\t\", num_habit_column, \"\\t\", str(round(num_habit_column * 100 / num_particle_ice,2))+\"%\")\n",
    "    print(\"Plate:\\t\\t\", num_habit_plate, \"\\t\", str(round(num_habit_plate * 100 / num_particle_ice,2))+\"%\")\n",
    "    print(\"Droplet:\\t\", num_habit_droplet, \"\\t\", str(round(num_habit_droplet * 100 / num_particle_ice,2))+\"%\")\n",
    "    print(\"Dropl.Lollipop:\\t\", num_habit_dropletLollipop, \"\\t\", str(round(num_habit_dropletLollipop * 100 / num_particle_ice,2))+\"%\")\n",
    "    print(\"Irregular:\\t\", num_habit_irregular, \"\\t\", str(round(num_habit_irregular * 100 / num_particle_ice,2))+\"%\")\n",
    "    print(\"Rosette:\\t\", num_habit_rosette, \"\\t\", str(round(num_habit_rosette * 100 / num_particle_ice,2))+\"%\")\n",
    "    print(\"PlateColumn:\\t\", num_habit_plateColumn, \"\\t\", str(round(num_habit_plateColumn * 100 / num_particle_ice,2))+\"%\")\n",
    "    print(\"Dendrite:\\t\", num_habit_dendrite, \"\\t\", str(round(num_habit_dendrite * 100 / num_particle_ice,2))+\"%\")\n",
    "    print(\"Lollipop:\\t\", num_habit_lollipop, \"\\t\", str(round(num_habit_lollipop * 100 / num_particle_ice,2))+\"%\")\n",
    "    print(\"Graupel:\\t\", num_habit_graupel, \"\\t\", str(round(num_habit_graupel * 100 / num_particle_ice,2))+\"%\")\n",
    "    print(\"Branch:\\t\\t\", num_habit_branch, \"\\t\", str(round(num_habit_branch * 100 / num_particle_ice,2))+\"%\")\n",
    "    print(\"Small:\\t\\t\", num_habit_small, \"\\t\", str(round(num_habit_small * 100 / num_particle_ice,2))+\"%\")\n",
    "    print(\"Recirculation:\\t\", num_habit_recirculation, \"\\t\", str(round(num_habit_recirculation * 100 / num_particle_ice,2))+\"%\")\n",
    "    print(\"Others:\\t\\t\", num_habit_others, \"\\t\", str(round(num_habit_others * 100 / num_particle_ice,2))+\"%\")\n",
    "    print(\"\")\n",
    "    \n",
    "    num_process_pristine = len(data[(data['label_proc_pristine'] == 1)].index)\n",
    "    num_process_aggregate = len(data[(data['label_proc_aggregate'] == 1)].index)\n",
    "    num_process_rimed = len(data[(data['label_proc_rimed'] == 1)].index)\n",
    "    num_process_aged = len(data[(data['label_proc_aged'] == 1)].index)\n",
    "    num_process_frozen = len(data[(data['label_proc_frozen'] == 1)].index)\n",
    "    \n",
    "    print(\"### Physical Process Information of Ice Particles ###\")\n",
    "    print(\"Pristine:\\t\", num_process_pristine, \"\\t\", str(round(num_process_pristine * 100 / num_particle_ice,2))+\"%\")\n",
    "    print(\"Aggregate:\\t\", num_process_aggregate, \"\\t\", str(round(num_process_aggregate * 100 / num_particle_ice,2))+\"%\")\n",
    "    print(\"Rimed:\\t\\t\", num_process_rimed, \"\\t\", str(round(num_process_rimed * 100 / num_particle_ice,2))+\"%\")\n",
    "    print(\"Aged:\\t\\t\", num_process_aged, \"\\t\", str(round(num_process_aged * 100 / num_particle_ice,2))+\"%\")\n",
    "    print(\"Frozen:\\t\\t\", num_process_frozen, \"\\t\", str(round(num_process_frozen * 100 / num_particle_ice,2))+\"%\")\n",
    "    \n",
    "print_statistic(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info(verbose=True)\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from holosuite/predict_pipeline/preprocessing.py\n",
    "def preprocess_img(img, img_size=-1):\n",
    "    \"\"\"Preprocess an image.\n",
    "    \n",
    "    The pixels of the image with NaN value are replaced with zeros. If `img_size` is not negative, the image is then\n",
    "    zero-padded to square shape and then scaled to `img_size`x`img_size`.\n",
    "    \n",
    "    Args:\n",
    "        img: An image array.\n",
    "        img_size: Dimensions of the output image (`img_size`x`img_size`), use -1 to keep the original dimensions.\n",
    "        \n",
    "    Returns:\n",
    "        The preprocessed image array.\n",
    "    \"\"\"\n",
    "    # Replace NaN entries with 0\n",
    "    img = np.nan_to_num(img)\n",
    "    if img_size < 0:\n",
    "        # Keep original size\n",
    "        prep_img = img\n",
    "    else:\n",
    "        # Pad and scale images\n",
    "        max_dim = max(img.shape)\n",
    "        pad_shape = (max_dim - img.shape[0], max_dim - img.shape[1])\n",
    "        pad_h_t = pad_shape[0]//2\n",
    "        pad_h_b = pad_shape[0]//2 + pad_shape[0]%2\n",
    "        pad_w_l = pad_shape[1]//2\n",
    "        pad_w_r = pad_shape[1]//2 + pad_shape[1]%2\n",
    "        square_img = np.pad(img, ((pad_h_t, pad_h_b), (pad_w_l, pad_w_r)), \"constant\", constant_values=0)\n",
    "        prep_img = ndimage.zoom(square_img, img_size/max_dim)\n",
    "    \n",
    "    return prep_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Small', [0, 0, 0, 0, 1]]\n",
      "['Plate Column', [1, 0, 0, 0, 0]]\n",
      "['Droplet Lollipop', [1, 0, 0, 0, 0]]\n",
      "['Out of focus', [1, 0, 0, 0, 0]]\n",
      "['Droplet', [0, 1, 0, 0, 0]]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# discard anything not ice\n",
    "# enter basic habit as string\n",
    "# enter physical process as one hot encoding:\n",
    "# 0 -> pristine\n",
    "# 1 -> aggregate\n",
    "# 2 -> rimed\n",
    "# 3 -> aged\n",
    "# 4 -> frozen\n",
    "# return as a list, empty list if not ice\n",
    "\n",
    "def encode_label(label):\n",
    "    basic_habit_dict = { \n",
    "        \"Column\": \"Column\",\n",
    "        \"column\": \"Column\",\n",
    "        \"Plate\": \"Plate\",\n",
    "        \"Plates\": \"Plate\",\n",
    "        \"Droplet\": \"Droplet\",\n",
    "        \"Droplets\": \"Droplet\",\n",
    "        \"Droplet Lollipop\": \"Droplet Lollipop\",\n",
    "        \"Irregular\": \"Irregular\",\n",
    "        \"Rosette\": \"Rosette\",\n",
    "        \"Plate Column\": \"Plate Column\",\n",
    "        \"Dendrite\": \"Dendrite\",\n",
    "        \"lollipop\": \"Lollipop\",\n",
    "        \"Graupel\": \"Graupel\",\n",
    "        \"Branch\": \"Branch\",\n",
    "        \"Small\": \"Small\",\n",
    "        \"Out\": \"Out of focus\", # out of focus\n",
    "        \"Recirculation\": \"Recirculation\",\n",
    "        \"Others\": \"=thers\",\n",
    "        \"Rimed\": \"Basic Habit: Rimed\", # Julies data\n",
    "        \"Aged\": \"Basic Habit: Aged\" # Julies data\n",
    "    }\n",
    "    physical_process_dict = {\n",
    "        \"pristine\": 0,\n",
    "        \"aggregate\": 1,\n",
    "        \"Aggregate\": 1,\n",
    "        \"rimed\": 2,\n",
    "        \"aged\": 3,\n",
    "        \"frozen\": 4\n",
    "    }\n",
    "    \n",
    "    original_label = label # for debugging, delet later\n",
    "    #print(original_label)\n",
    "    label_list = []\n",
    "    particle_label, label = split_labels(label)\n",
    "    if particle_label != \"Ice\" or label == -1: # not Ice or no basic habit defined\n",
    "        return []\n",
    "    \n",
    "    habit_label, label = split_labels(label)\n",
    "    if habit_label not in basic_habit_dict:\n",
    "        print(habit_label, \"not in habit dictionary\", original_label)\n",
    "        return []\n",
    "    # extra clause because Ice_Out_Of_Focus, the _ causes a problem with the destinction between habit and process\n",
    "    if (habit_label == \"Out\"):\n",
    "        _, label = split_labels(label)\n",
    "        _, label = split_labels(label)\n",
    "    # extra clause because plate column are sometimes labeled as \"plates_columns\", and the _ causes a problem with the destinction between habit and process\n",
    "    if (habit_label == \"Plates\" or habit_label == \"plates\") and label[:6] == \"column\":\n",
    "        _, label = split_labels(label)\n",
    "        habit_label = \"Plate Column\"\n",
    "    # extra clause because Droplet lollipop column are sometimes labeled as \"Droplet_lollipop\", and the _ causes a problem with the destinction between habit and process\n",
    "    if (habit_label == \"Droplet\" or habit_label == \"Droplets\") and label[:8] == \"lollipop\":\n",
    "        _, label = split_labels(label)\n",
    "        habit_label = \"Droplet Lollipop\"\n",
    "    \n",
    "    physical_process_list = [0,0,0,0,0]\n",
    "    label_list.append(basic_habit_dict[habit_label])\n",
    "    if label == -1: # no physical process defined -> pristine\n",
    "        physical_process_list[0] = 1\n",
    "        label_list.append(physical_process_list)\n",
    "        return label_list\n",
    "    \n",
    "    process_label, label = split_labels(label)\n",
    "    if process_label not in physical_process_dict:\n",
    "        print(process_label, \"not in physical process dictionary \", original_label)\n",
    "        return []  #empty list \n",
    "    \n",
    "    while label != -1:\n",
    "        physical_process_list[physical_process_dict[process_label]] = 1\n",
    "        process_label, label = split_labels(label)\n",
    "    physical_process_list[physical_process_dict[process_label]] = 1\n",
    "    \n",
    "    # perform some checks:\n",
    "    # at least one physical process is set ( if no process, then pristine should be set)\n",
    "    assert physical_process_list[0] or physical_process_list[1] or physical_process_list[2] or physical_process_list[3] or physical_process_list[4] or physical_process_list[5]\n",
    "    # either not pristine, or not any of the others\n",
    "    assert physical_process_list[0] == 0 or (not physical_process_list[1] and not physical_process_list[2] and not physical_process_list[3] and not physical_process_list[4] and not physical_process_list[5])\n",
    "    label_list.append(physical_process_list)\n",
    "    return label_list\n",
    "    \n",
    "\n",
    "    \n",
    "# split_labels returns a split of the label around a '_'\n",
    "# eg. split_labels(abcd_efg_h) = abcd, efg_h\n",
    "# first return is a guaranteed to be a valid string, second return is -1 if there is no '_' present, else it is a valid string\n",
    "# eg. split_labels(abcdef) = abcdef, -1\n",
    "def split_labels(old_label):\n",
    "    i = old_label.find('_')\n",
    "    if i == -1:\n",
    "        return old_label, -1\n",
    "    else:\n",
    "        return old_label[:i], old_label[i+1:]\n",
    "    \n",
    "\n",
    "print(encode_label(\"Ice_Small_frozen\"))\n",
    "print(encode_label(\"Ice_Plates_columns\"))\n",
    "print(encode_label(\"Ice_Droplet_lollipop\"))\n",
    "print(encode_label(\"Ice_Out_Of_Focus\"))\n",
    "print(encode_label(\"Ice_Droplet_aggregate\"))\n",
    "print(encode_label(\"Smt_Droplet_frozen\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_label_old(label):\n",
    "    # use a dicts to quickly add/change/merge habits and add new spellings of habits\n",
    "    particle_dict = {\n",
    "        \"Ice\": 0,\n",
    "        \"Water\": 1,\n",
    "        \"No\": \"No Ice\", # No_Ice\n",
    "        \"Artifact\": \"Artifact\",\n",
    "        \"Unsure\": \"Unsure\",\n",
    "        \"Unknown\": \"Unknown\"       \n",
    "    }\n",
    "    basic_habit_dict = { \n",
    "        \"Column\": \"Column\",\n",
    "        \"column\": \"Column\",\n",
    "        \"Plate\": \"Plate\",\n",
    "        \"Plates\": \"Plate\",\n",
    "        \"Droplet\": \"Droplet\",\n",
    "        \"Droplets\": \"Droplet\",\n",
    "        \"Droplet lollipop\": \"Droplet Lollipop\",\n",
    "        \"Irregular\": \"Irregular\",\n",
    "        \"Rosette\": \"Rosette\",\n",
    "        \"Plate Column\": \"Plate Column\",\n",
    "        \"Dendrite\": \"Dendrite\",\n",
    "        \"lollipop\": \"Lollipop\",\n",
    "        \"Graupel\": \"Graupel\",\n",
    "        \"Branch\": \"Branch\",\n",
    "        \"Small\": \"Small\",\n",
    "        \"Out\": \"Out of focus\", # out of focus\n",
    "        \"Recirculation\": \"Recirculation\",\n",
    "        \"Others\": \"Others\",\n",
    "        \"Rimed\": \"Basic Habit: Rimed\", # Julies data\n",
    "        \"Aged\": \"Basic Habit: Aged\" # Julies data\n",
    "    }\n",
    "    physical_process_dict = {\n",
    "        \"pristine\": 0,\n",
    "        \"aggregate\": 1,\n",
    "        \"Aggregate\": 1,\n",
    "        \"rimed\": 2,\n",
    "        \"aged\": 3,\n",
    "        \"frozen\": 4\n",
    "    }\n",
    "\n",
    "    original_label = label # for debugging purposes, delete later!\n",
    "    \n",
    "    # get num of distinguishable values in dictionary \n",
    "    num_physical_processes = len(set(physical_process_dict.values()))\n",
    "    \n",
    "    # determine particle type\n",
    "    particle_label, label = split_labels(label)\n",
    "    if particle_label not in particle_dict:\n",
    "        print(particle_label, \"not in particle dictionary\", original_label)\n",
    "        return -1, -1, np.full(shape=num_physical_processes, fill_value=-1, dtype=np.int)\n",
    "    if label == -1 or particle_label == \"No\": # no basic habit defined or No_Ice (also no habit defined)\n",
    "        return particle_dict[particle_label], -1,  np.full(shape=num_physical_processes, fill_value=-1, dtype=np.int)\n",
    "    \n",
    "    # determine habit\n",
    "    habit_label, label = split_labels(label)\n",
    "    if habit_label not in basic_habit_dict:\n",
    "        print(habit_label, \"not in habit dictionary\", original_label)\n",
    "        return particle_dict[particle_label], -1,  np.full(shape=num_physical_processes, fill_value=-1, dtype=np.int)\n",
    "    if label == -1: # no physical process defined -> pristine\n",
    "        physical_process_encoding = np.full(shape=num_physical_processes, fill_value=0, dtype=np.int)\n",
    "        physical_process_encoding[physical_process_dict[\"pristine\"]] = 1\n",
    "        return particle_dict[particle_label], basic_habit_dict[habit_label], physical_process_encoding\n",
    "    \n",
    "    # extra clause because Ice_Out_Of_Focus, the _ causes a problem with the destinction between habit and process\n",
    "    if (habit_label == \"Out\"):\n",
    "        return particle_dict[particle_label], basic_habit_dict[habit_label], np.full(shape=num_physical_processes, fill_value=-1, dtype=np.int)\n",
    "        \n",
    "    # extra clause because plate column are sometimes labeled as \"plates_columns\", and the _ causes a problem with the destinction between habit and process\n",
    "    if (habit_label == \"Plates\" or habit_label == \"plates\") and label[:6] == \"column\":\n",
    "        _, label = split_labels(label)\n",
    "        habit_label = \"Plate Column\"\n",
    "        if label == -1: # no physical process defined -> pristine\n",
    "            physical_process_encoding = np.full(shape=num_physical_processes, fill_value=0, dtype=np.int)\n",
    "            physical_process_encoding[physical_process_dict[\"pristine\"]] = 1\n",
    "            return particle_dict[particle_label], basic_habit_dict[habit_label], physical_process_encoding\n",
    "\n",
    "    # extra clause because Droplet lollipop column are sometimes labeled as \"Droplet_lollipop\", and the _ causes a problem with the destinction between habit and process\n",
    "    if (habit_label == \"Droplet\" or habit_label == \"Droplets\") and label[:8] == \"lollipop\":\n",
    "        _, label = split_labels(label)\n",
    "        habit_label = \"Droplet lollipop\"\n",
    "        if label == -1: # no physical process defined -> pristine\n",
    "            physical_process_encoding = np.full(shape=num_physical_processes, fill_value=0, dtype=np.int)\n",
    "            physical_process_encoding[physical_process_dict[\"pristine\"]] = 1\n",
    "            return particle_dict[particle_label], basic_habit_dict[habit_label], physical_process_encoding\n",
    "        \n",
    "    # determine physical processes -> can be multiple\n",
    "    physical_process_encoding = np.full(shape=num_physical_processes, fill_value=0, dtype=np.int)\n",
    "    process_label, label = split_labels(label)\n",
    "    if process_label not in physical_process_dict:\n",
    "        print(process_label, \"not in physical process dictionary \", original_label)\n",
    "        return particle_dict[particle_label], basic_habit_dict[habit_label], np.full(shape=num_physical_processes, fill_value=-1, dtype=np.int)  \n",
    "    \n",
    "    while label != -1:\n",
    "        physical_process_encoding[physical_process_dict[process_label]] = 1\n",
    "        process_label, label = split_labels(label)\n",
    "    physical_process_encoding[physical_process_dict[process_label]] = 1\n",
    "\n",
    "    return particle_dict[particle_label], basic_habit_dict[habit_label], physical_process_encoding\n",
    "\n",
    "\n",
    "# split_labels returns a split of the label around a '_'\n",
    "# eg. split_labels(abcd_efg_h) = abcd, efg_h\n",
    "# first return is a guaranteed to be a valid string, second return is -1 if there is no '_' present, else it is a valid string\n",
    "# eg. split_labels(abcdef) = abcdef, -1\n",
    "def split_labels(old_label):\n",
    "    i = old_label.find('_')\n",
    "    if i == -1:\n",
    "        return old_label, -1\n",
    "    else:\n",
    "        return old_label[:i], old_label[i+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    directory = os.getcwd()\n",
    "    file_paths = []\n",
    "    file_paths.append(directory + \"/../data/huiying_labeled/huiying_part1.mat\")\n",
    "    #file_paths.append(directory + \"/../data/huiying_labeled/huiying_part2.mat\")\n",
    "    #file_paths.append(directory + \"/../data/huiying_labeled/huiying_part3.mat\")\n",
    "    #file_paths.append(directory + \"/../data/julie_labeled/julie_part1.mat\")\n",
    "    #file_paths.append(directory + \"/../data/julie_labeled/julie_part2.mat\")\n",
    "    #file_paths.append(directory + \"/../data/julie_labeled/julie_part3.mat\")\n",
    "    #file_path = directory + \"/../data/huiying_labeled/huiying_part1.mat\"\n",
    "\n",
    "    # load data like in holosuite/predict_pipeline/preprocessing.py\n",
    "    data_index = []\n",
    "    data_dict = {\"img\": [], \"label\":[]}\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        print(file_path)\n",
    "\n",
    "\n",
    "        var = io.whosmat(file_path)[0][0]\n",
    "        mat = io.loadmat(file_path, squeeze_me=True, struct_as_record=False)\n",
    "        ids = mat[var].prtclID\n",
    "        imgs = mat[var].prtclIm\n",
    "        labels = mat[var].cpType\n",
    "\n",
    "        for j, (id_, img, label) in enumerate(zip(ids, imgs, labels)):\n",
    "            # Check for missing IDs\n",
    "            if isinstance(id_, np.ndarray):\n",
    "                id_ = \"no_id_{}\".format(j + 1)\n",
    "                print(\"prtclID missing in row {}, substituting with '{}'\".format(j + 1, id_))\n",
    "            # Check for duplicate IDs\n",
    "            if id_ in data_index:\n",
    "                print(\"ID {} not unique\".format(id_))\n",
    "\n",
    "            \n",
    "            #data_dict[\"label\"].append(encode_label(label))\n",
    "            \n",
    "            label = encode_label(label)\n",
    "            if len(label) != 0:\n",
    "                data_index.append(id_)\n",
    "                data_dict[\"label\"].append(label)\n",
    "                data_dict[\"img\"].append(img)\n",
    "\n",
    "    dataset = pd.DataFrame(data_dict, index=data_index)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
