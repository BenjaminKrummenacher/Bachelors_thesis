{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-26 19:24:28.472421: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-01-26 19:24:28.472446: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "#import tensorflow_addons as tfa\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "import sklearn.metrics as metrics\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import time\n",
    "import os\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7655\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data\n",
      "                                                       shape  size  \\\n",
      "2019-11-11-18-45-13-933153_+2.33_+3.65_+72.70_+...  (30, 35)    35   \n",
      "2019-11-11-18-15-16-181618_+3.86_-5.25_+62.10_+...  (62, 29)    62   \n",
      "\n",
      "                                                                                              img_abs  \\\n",
      "2019-11-11-18-45-13-933153_+2.33_+3.65_+72.70_+...  [[2.7054569e-20, 2.1304332e-18, 3.447854e-18, ...   \n",
      "2019-11-11-18-15-16-181618_+3.86_-5.25_+62.10_+...  [[3.740776e-26, -8.6513574e-14, -2.6216236e-14...   \n",
      "\n",
      "                                                                                              img_ang  \\\n",
      "2019-11-11-18-45-13-933153_+2.33_+3.65_+72.70_+...  [[-2.1548317e-19, -1.2919434e-20, 1.502107e-19...   \n",
      "2019-11-11-18-15-16-181618_+3.86_-5.25_+62.10_+...  [[3.7774554e-27, 9.6614924e-15, 2.927725e-15, ...   \n",
      "\n",
      "                                                   label_habit  \\\n",
      "2019-11-11-18-45-13-933153_+2.33_+3.65_+72.70_+...      Column   \n",
      "2019-11-11-18-15-16-181618_+3.86_-5.25_+62.10_+...      Column   \n",
      "\n",
      "                                                    label_proc_pristine  \\\n",
      "2019-11-11-18-45-13-933153_+2.33_+3.65_+72.70_+...                    1   \n",
      "2019-11-11-18-15-16-181618_+3.86_-5.25_+62.10_+...                    1   \n",
      "\n",
      "                                                    label_proc_aggregate  \\\n",
      "2019-11-11-18-45-13-933153_+2.33_+3.65_+72.70_+...                     0   \n",
      "2019-11-11-18-15-16-181618_+3.86_-5.25_+62.10_+...                     0   \n",
      "\n",
      "                                                    label_proc_rimed  \\\n",
      "2019-11-11-18-45-13-933153_+2.33_+3.65_+72.70_+...                 0   \n",
      "2019-11-11-18-15-16-181618_+3.86_-5.25_+62.10_+...                 0   \n",
      "\n",
      "                                                    label_proc_aged  \\\n",
      "2019-11-11-18-45-13-933153_+2.33_+3.65_+72.70_+...                0   \n",
      "2019-11-11-18-15-16-181618_+3.86_-5.25_+62.10_+...                0   \n",
      "\n",
      "                                                    label_proc_frozen  \n",
      "2019-11-11-18-45-13-933153_+2.33_+3.65_+72.70_+...                  0  \n",
      "2019-11-11-18-15-16-181618_+3.86_-5.25_+62.10_+...                  0  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                                                         shape  size  \\\n",
       " 2019-11-11-18-24-56-506537_-3.86_+1.12_+72.50_+...    (39, 17)    39   \n",
       " 2019-11-11-17-46-40-86260_-5.52_+6.34_+35.30_+86.5    (53, 22)    53   \n",
       " 2019-11-11-17-03-02-700523_-0.96_+5.50_+88.70_+...  (128, 136)   136   \n",
       " 2019-11-11-18-29-05-0148_+2.45_-5.28_+20.40_+63.1     (38, 22)    38   \n",
       " 2019-11-11-18-37-20-488412_+2.68_-1.98_+98.60_+...  (374, 210)   374   \n",
       " ...                                                        ...   ...   \n",
       " 2019-11-11-18-13-12-266114_-3.56_+0.81_+87.00_+...    (56, 66)    66   \n",
       " 2019-11-11-17-54-52-68138_+3.42_+0.94_+26.20_+2...   (102, 65)   102   \n",
       " 2019-11-11-18-31-18-765706_+1.42_-2.41_+23.20_+...   (35, 134)   134   \n",
       " 2019-11-11-18-17-05-569446_-0.06_-6.22_+60.10_+...  (339, 198)   339   \n",
       " 2019-11-11-18-26-25-51437_+1.97_-4.61_+55.40_+1...    (40, 96)    96   \n",
       " \n",
       "                                                                                               img_abs  \\\n",
       " 2019-11-11-18-24-56-506537_-3.86_+1.12_+72.50_+...  [[-2.4893165e-24, -1.5813004e-10, -3.6245537e-...   \n",
       " 2019-11-11-17-46-40-86260_-5.52_+6.34_+35.30_+86.5  [[-3.2941513e-25, 6.758144e-11, 8.28999e-11, -...   \n",
       " 2019-11-11-17-03-02-700523_-0.96_+5.50_+88.70_+...  [[0.0, 0.0, -0.0, 0.0, -0.0, 0.0, -0.0, 0.0, -...   \n",
       " 2019-11-11-18-29-05-0148_+2.45_-5.28_+20.40_+63.1   [[-2.033165e-23, 6.3067014e-09, 1.4855786e-08,...   \n",
       " 2019-11-11-18-37-20-488412_+2.68_-1.98_+98.60_+...  [[-0.0, -0.0, 0.0, -0.0, 0.0, -0.0, 0.0, -0.0,...   \n",
       " ...                                                                                               ...   \n",
       " 2019-11-11-18-13-12-266114_-3.56_+0.81_+87.00_+...  [[6.5213124e-23, 1.6131293e-21, -3.6501765e-22...   \n",
       " 2019-11-11-17-54-52-68138_+3.42_+0.94_+26.20_+2...  [[3e-45, 1.16834595e-32, -6.0473154e-32, 1.762...   \n",
       " 2019-11-11-18-31-18-765706_+1.42_-2.41_+23.20_+...  [[-0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, -0...   \n",
       " 2019-11-11-18-17-05-569446_-0.06_-6.22_+60.10_+...  [[0.0, 0.0, -0.0, -0.0, 0.0, -0.0, -0.0, 0.0, ...   \n",
       " 2019-11-11-18-26-25-51437_+1.97_-4.61_+55.40_+1...  [[-2.7365342e-35, -2.043827e-34, 1.7163336e-33...   \n",
       " \n",
       "                                                                                               img_ang  \\\n",
       " 2019-11-11-18-24-56-506537_-3.86_+1.12_+72.50_+...  [[-1.7554214e-26, -5.723239e-11, -1.3118436e-1...   \n",
       " 2019-11-11-17-46-40-86260_-5.52_+6.34_+35.30_+86.5  [[-8.0501986e-26, 2.955654e-11, 3.6256026e-11,...   \n",
       " 2019-11-11-17-03-02-700523_-0.96_+5.50_+88.70_+...  [[-0.0, 0.0, -0.0, 0.0, -0.0, 0.0, -0.0, 0.0, ...   \n",
       " 2019-11-11-18-29-05-0148_+2.45_-5.28_+20.40_+63.1   [[-2.8587264e-24, 6.128222e-10, 1.4435367e-09,...   \n",
       " 2019-11-11-18-37-20-488412_+2.68_-1.98_+98.60_+...  [[-0.0, -0.0, 0.0, -0.0, 0.0, -0.0, 0.0, -0.0,...   \n",
       " ...                                                                                               ...   \n",
       " 2019-11-11-18-13-12-266114_-3.56_+0.81_+87.00_+...  [[5.941532e-23, 8.875891e-22, -3.4150256e-22, ...   \n",
       " 2019-11-11-17-54-52-68138_+3.42_+0.94_+26.20_+2...  [[-3e-45, 1.1843142e-32, -6.129967e-32, 1.7868...   \n",
       " 2019-11-11-18-31-18-765706_+1.42_-2.41_+23.20_+...  [[-0.0, -0.0, 0.0, 0.0, 0.0, 0.0, -0.0, -0.0, ...   \n",
       " 2019-11-11-18-17-05-569446_-0.06_-6.22_+60.10_+...  [[-0.0, 0.0, -0.0, -0.0, 0.0, -0.0, -0.0, 0.0,...   \n",
       " 2019-11-11-18-26-25-51437_+1.97_-4.61_+55.40_+1...  [[-4.3839313e-35, -1.4218001e-34, 5.7385283e-3...   \n",
       " \n",
       "                                                    label_habit  \\\n",
       " 2019-11-11-18-24-56-506537_-3.86_+1.12_+72.50_+...      Column   \n",
       " 2019-11-11-17-46-40-86260_-5.52_+6.34_+35.30_+86.5      Column   \n",
       " 2019-11-11-17-03-02-700523_-0.96_+5.50_+88.70_+...      Column   \n",
       " 2019-11-11-18-29-05-0148_+2.45_-5.28_+20.40_+63.1       Column   \n",
       " 2019-11-11-18-37-20-488412_+2.68_-1.98_+98.60_+...      Column   \n",
       " ...                                                        ...   \n",
       " 2019-11-11-18-13-12-266114_-3.56_+0.81_+87.00_+...      Column   \n",
       " 2019-11-11-17-54-52-68138_+3.42_+0.94_+26.20_+2...      Column   \n",
       " 2019-11-11-18-31-18-765706_+1.42_-2.41_+23.20_+...      Column   \n",
       " 2019-11-11-18-17-05-569446_-0.06_-6.22_+60.10_+...      Column   \n",
       " 2019-11-11-18-26-25-51437_+1.97_-4.61_+55.40_+1...      Column   \n",
       " \n",
       "                                                     label_proc_pristine  \\\n",
       " 2019-11-11-18-24-56-506537_-3.86_+1.12_+72.50_+...                    1   \n",
       " 2019-11-11-17-46-40-86260_-5.52_+6.34_+35.30_+86.5                    1   \n",
       " 2019-11-11-17-03-02-700523_-0.96_+5.50_+88.70_+...                    0   \n",
       " 2019-11-11-18-29-05-0148_+2.45_-5.28_+20.40_+63.1                     0   \n",
       " 2019-11-11-18-37-20-488412_+2.68_-1.98_+98.60_+...                    0   \n",
       " ...                                                                 ...   \n",
       " 2019-11-11-18-13-12-266114_-3.56_+0.81_+87.00_+...                    1   \n",
       " 2019-11-11-17-54-52-68138_+3.42_+0.94_+26.20_+2...                    1   \n",
       " 2019-11-11-18-31-18-765706_+1.42_-2.41_+23.20_+...                    0   \n",
       " 2019-11-11-18-17-05-569446_-0.06_-6.22_+60.10_+...                    0   \n",
       " 2019-11-11-18-26-25-51437_+1.97_-4.61_+55.40_+1...                    1   \n",
       " \n",
       "                                                     label_proc_aggregate  \\\n",
       " 2019-11-11-18-24-56-506537_-3.86_+1.12_+72.50_+...                     0   \n",
       " 2019-11-11-17-46-40-86260_-5.52_+6.34_+35.30_+86.5                     0   \n",
       " 2019-11-11-17-03-02-700523_-0.96_+5.50_+88.70_+...                     1   \n",
       " 2019-11-11-18-29-05-0148_+2.45_-5.28_+20.40_+63.1                      0   \n",
       " 2019-11-11-18-37-20-488412_+2.68_-1.98_+98.60_+...                     0   \n",
       " ...                                                                  ...   \n",
       " 2019-11-11-18-13-12-266114_-3.56_+0.81_+87.00_+...                     0   \n",
       " 2019-11-11-17-54-52-68138_+3.42_+0.94_+26.20_+2...                     0   \n",
       " 2019-11-11-18-31-18-765706_+1.42_-2.41_+23.20_+...                     1   \n",
       " 2019-11-11-18-17-05-569446_-0.06_-6.22_+60.10_+...                     1   \n",
       " 2019-11-11-18-26-25-51437_+1.97_-4.61_+55.40_+1...                     0   \n",
       " \n",
       "                                                     label_proc_rimed  \\\n",
       " 2019-11-11-18-24-56-506537_-3.86_+1.12_+72.50_+...                 0   \n",
       " 2019-11-11-17-46-40-86260_-5.52_+6.34_+35.30_+86.5                 0   \n",
       " 2019-11-11-17-03-02-700523_-0.96_+5.50_+88.70_+...                 0   \n",
       " 2019-11-11-18-29-05-0148_+2.45_-5.28_+20.40_+63.1                  0   \n",
       " 2019-11-11-18-37-20-488412_+2.68_-1.98_+98.60_+...                 0   \n",
       " ...                                                              ...   \n",
       " 2019-11-11-18-13-12-266114_-3.56_+0.81_+87.00_+...                 0   \n",
       " 2019-11-11-17-54-52-68138_+3.42_+0.94_+26.20_+2...                 0   \n",
       " 2019-11-11-18-31-18-765706_+1.42_-2.41_+23.20_+...                 0   \n",
       " 2019-11-11-18-17-05-569446_-0.06_-6.22_+60.10_+...                 0   \n",
       " 2019-11-11-18-26-25-51437_+1.97_-4.61_+55.40_+1...                 0   \n",
       " \n",
       "                                                     label_proc_aged  \\\n",
       " 2019-11-11-18-24-56-506537_-3.86_+1.12_+72.50_+...                0   \n",
       " 2019-11-11-17-46-40-86260_-5.52_+6.34_+35.30_+86.5                0   \n",
       " 2019-11-11-17-03-02-700523_-0.96_+5.50_+88.70_+...                1   \n",
       " 2019-11-11-18-29-05-0148_+2.45_-5.28_+20.40_+63.1                 1   \n",
       " 2019-11-11-18-37-20-488412_+2.68_-1.98_+98.60_+...                1   \n",
       " ...                                                             ...   \n",
       " 2019-11-11-18-13-12-266114_-3.56_+0.81_+87.00_+...                0   \n",
       " 2019-11-11-17-54-52-68138_+3.42_+0.94_+26.20_+2...                0   \n",
       " 2019-11-11-18-31-18-765706_+1.42_-2.41_+23.20_+...                0   \n",
       " 2019-11-11-18-17-05-569446_-0.06_-6.22_+60.10_+...                0   \n",
       " 2019-11-11-18-26-25-51437_+1.97_-4.61_+55.40_+1...                0   \n",
       " \n",
       "                                                     label_proc_frozen  \n",
       " 2019-11-11-18-24-56-506537_-3.86_+1.12_+72.50_+...                  0  \n",
       " 2019-11-11-17-46-40-86260_-5.52_+6.34_+35.30_+86.5                  0  \n",
       " 2019-11-11-17-03-02-700523_-0.96_+5.50_+88.70_+...                  0  \n",
       " 2019-11-11-18-29-05-0148_+2.45_-5.28_+20.40_+63.1                   0  \n",
       " 2019-11-11-18-37-20-488412_+2.68_-1.98_+98.60_+...                  0  \n",
       " ...                                                               ...  \n",
       " 2019-11-11-18-13-12-266114_-3.56_+0.81_+87.00_+...                  0  \n",
       " 2019-11-11-17-54-52-68138_+3.42_+0.94_+26.20_+2...                  0  \n",
       " 2019-11-11-18-31-18-765706_+1.42_-2.41_+23.20_+...                  0  \n",
       " 2019-11-11-18-17-05-569446_-0.06_-6.22_+60.10_+...                  0  \n",
       " 2019-11-11-18-26-25-51437_+1.97_-4.61_+55.40_+1...                  0  \n",
       " \n",
       " [7064 rows x 10 columns],\n",
       "                                                          shape  size  \\\n",
       " 2019-11-11-18-45-13-933153_+2.33_+3.65_+72.70_+...    (30, 35)    35   \n",
       " 2019-11-11-18-15-16-181618_+3.86_-5.25_+62.10_+...    (62, 29)    62   \n",
       " 2019-11-11-17-26-44-366119_-1.57_-1.58_+82.70_+...   (121, 62)   121   \n",
       " 2019-11-11-18-49-39-136200_-0.53_+4.32_+42.00_+...    (43, 42)    43   \n",
       " 2019-11-11-18-33-59-261512_+5.11_+2.22_+27.00_+...  (130, 241)   241   \n",
       " ...                                                        ...   ...   \n",
       " 2019-11-11-18-39-00-862256_+6.58_-5.98_+80.50_+...    (59, 52)    59   \n",
       " 2019-11-11-18-25-15-378611_+4.02_+6.50_+55.50_+...    (74, 40)    74   \n",
       " 2019-11-11-17-00-10-687106_+2.27_+6.26_+55.40_+...   (77, 275)   275   \n",
       " 2019-11-11-16-27-51-150735_-4.56_+3.79_+86.50_+...    (73, 76)    76   \n",
       " 2019-11-11-16-08-04-450565_+2.27_-4.01_+43.00_+...   (73, 139)   139   \n",
       " \n",
       "                                                                                               img_abs  \\\n",
       " 2019-11-11-18-45-13-933153_+2.33_+3.65_+72.70_+...  [[2.7054569e-20, 2.1304332e-18, 3.447854e-18, ...   \n",
       " 2019-11-11-18-15-16-181618_+3.86_-5.25_+62.10_+...  [[3.740776e-26, -8.6513574e-14, -2.6216236e-14...   \n",
       " 2019-11-11-17-26-44-366119_-1.57_-1.58_+82.70_+...  [[-0.0, 3.191e-42, -2.3333e-41, 1.17942e-40, -...   \n",
       " 2019-11-11-18-49-39-136200_-0.53_+4.32_+42.00_+...  [[1.3363667e-22, -1.4653036e-10, -2.9650848e-1...   \n",
       " 2019-11-11-18-33-59-261512_+5.11_+2.22_+27.00_+...  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...   \n",
       " ...                                                                                               ...   \n",
       " 2019-11-11-18-39-00-862256_+6.58_-5.98_+80.50_+...  [[-3.3362688e-21, 2.216405e-06, 1.4133597e-06,...   \n",
       " 2019-11-11-18-25-15-378611_+4.02_+6.50_+55.50_+...  [[-3.9225858e-28, 2.9099085e-14, -3.8179922e-1...   \n",
       " 2019-11-11-17-00-10-687106_+2.27_+6.26_+55.40_+...  [[-0.0, 0.0, 0.0, 0.0, 0.0, -0.0, -0.0, 0.0, 0...   \n",
       " 2019-11-11-16-27-51-150735_-4.56_+3.79_+86.50_+...  [[4e-45, 1.3e-44, -2e-44, -7.1e-44, 1.22e-43, ...   \n",
       " 2019-11-11-16-08-04-450565_+2.27_-4.01_+43.00_+...  [[7.85e-43, 6.2215e-41, -4.17319e-40, 3.92234e...   \n",
       " \n",
       "                                                                                               img_ang  \\\n",
       " 2019-11-11-18-45-13-933153_+2.33_+3.65_+72.70_+...  [[-2.1548317e-19, -1.2919434e-20, 1.502107e-19...   \n",
       " 2019-11-11-18-15-16-181618_+3.86_-5.25_+62.10_+...  [[3.7774554e-27, 9.6614924e-15, 2.927725e-15, ...   \n",
       " 2019-11-11-17-26-44-366119_-1.57_-1.58_+82.70_+...  [[0.0, -3.98e-43, 2.909e-42, -1.4702e-41, 6.52...   \n",
       " 2019-11-11-18-49-39-136200_-0.53_+4.32_+42.00_+...  [[-9.122569e-24, -5.0208736e-11, -1.01598854e-...   \n",
       " 2019-11-11-18-33-59-261512_+5.11_+2.22_+27.00_+...  [[-0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       " ...                                                                                               ...   \n",
       " 2019-11-11-18-39-00-862256_+6.58_-5.98_+80.50_+...  [[4.489681e-21, 3.4297875e-07, 2.1871108e-07, ...   \n",
       " 2019-11-11-18-25-15-378611_+4.02_+6.50_+55.50_+...  [[3.1621772e-29, -5.0418594e-15, 6.6152528e-15...   \n",
       " 2019-11-11-17-00-10-687106_+2.27_+6.26_+55.40_+...  [[-0.0, 0.0, 0.0, 0.0, -0.0, -0.0, -0.0, 0.0, ...   \n",
       " 2019-11-11-16-27-51-150735_-4.56_+3.79_+86.50_+...  [[0.0, 8e-45, -2.2e-44, -4e-44, 8.1e-44, 2.55e...   \n",
       " 2019-11-11-16-08-04-450565_+2.27_-4.01_+43.00_+...  [[-5.9454e-41, 2.17029e-40, -9.42505e-40, 6.72...   \n",
       " \n",
       "                                                    label_habit  \\\n",
       " 2019-11-11-18-45-13-933153_+2.33_+3.65_+72.70_+...      Column   \n",
       " 2019-11-11-18-15-16-181618_+3.86_-5.25_+62.10_+...      Column   \n",
       " 2019-11-11-17-26-44-366119_-1.57_-1.58_+82.70_+...      Column   \n",
       " 2019-11-11-18-49-39-136200_-0.53_+4.32_+42.00_+...      Column   \n",
       " 2019-11-11-18-33-59-261512_+5.11_+2.22_+27.00_+...      Column   \n",
       " ...                                                        ...   \n",
       " 2019-11-11-18-39-00-862256_+6.58_-5.98_+80.50_+...      Column   \n",
       " 2019-11-11-18-25-15-378611_+4.02_+6.50_+55.50_+...      Column   \n",
       " 2019-11-11-17-00-10-687106_+2.27_+6.26_+55.40_+...      Column   \n",
       " 2019-11-11-16-27-51-150735_-4.56_+3.79_+86.50_+...      Column   \n",
       " 2019-11-11-16-08-04-450565_+2.27_-4.01_+43.00_+...      Column   \n",
       " \n",
       "                                                     label_proc_pristine  \\\n",
       " 2019-11-11-18-45-13-933153_+2.33_+3.65_+72.70_+...                    1   \n",
       " 2019-11-11-18-15-16-181618_+3.86_-5.25_+62.10_+...                    1   \n",
       " 2019-11-11-17-26-44-366119_-1.57_-1.58_+82.70_+...                    0   \n",
       " 2019-11-11-18-49-39-136200_-0.53_+4.32_+42.00_+...                    1   \n",
       " 2019-11-11-18-33-59-261512_+5.11_+2.22_+27.00_+...                    0   \n",
       " ...                                                                 ...   \n",
       " 2019-11-11-18-39-00-862256_+6.58_-5.98_+80.50_+...                    1   \n",
       " 2019-11-11-18-25-15-378611_+4.02_+6.50_+55.50_+...                    0   \n",
       " 2019-11-11-17-00-10-687106_+2.27_+6.26_+55.40_+...                    0   \n",
       " 2019-11-11-16-27-51-150735_-4.56_+3.79_+86.50_+...                    1   \n",
       " 2019-11-11-16-08-04-450565_+2.27_-4.01_+43.00_+...                    0   \n",
       " \n",
       "                                                     label_proc_aggregate  \\\n",
       " 2019-11-11-18-45-13-933153_+2.33_+3.65_+72.70_+...                     0   \n",
       " 2019-11-11-18-15-16-181618_+3.86_-5.25_+62.10_+...                     0   \n",
       " 2019-11-11-17-26-44-366119_-1.57_-1.58_+82.70_+...                     0   \n",
       " 2019-11-11-18-49-39-136200_-0.53_+4.32_+42.00_+...                     0   \n",
       " 2019-11-11-18-33-59-261512_+5.11_+2.22_+27.00_+...                     1   \n",
       " ...                                                                  ...   \n",
       " 2019-11-11-18-39-00-862256_+6.58_-5.98_+80.50_+...                     0   \n",
       " 2019-11-11-18-25-15-378611_+4.02_+6.50_+55.50_+...                     0   \n",
       " 2019-11-11-17-00-10-687106_+2.27_+6.26_+55.40_+...                     0   \n",
       " 2019-11-11-16-27-51-150735_-4.56_+3.79_+86.50_+...                     0   \n",
       " 2019-11-11-16-08-04-450565_+2.27_-4.01_+43.00_+...                     0   \n",
       " \n",
       "                                                     label_proc_rimed  \\\n",
       " 2019-11-11-18-45-13-933153_+2.33_+3.65_+72.70_+...                 0   \n",
       " 2019-11-11-18-15-16-181618_+3.86_-5.25_+62.10_+...                 0   \n",
       " 2019-11-11-17-26-44-366119_-1.57_-1.58_+82.70_+...                 0   \n",
       " 2019-11-11-18-49-39-136200_-0.53_+4.32_+42.00_+...                 0   \n",
       " 2019-11-11-18-33-59-261512_+5.11_+2.22_+27.00_+...                 0   \n",
       " ...                                                              ...   \n",
       " 2019-11-11-18-39-00-862256_+6.58_-5.98_+80.50_+...                 0   \n",
       " 2019-11-11-18-25-15-378611_+4.02_+6.50_+55.50_+...                 1   \n",
       " 2019-11-11-17-00-10-687106_+2.27_+6.26_+55.40_+...                 0   \n",
       " 2019-11-11-16-27-51-150735_-4.56_+3.79_+86.50_+...                 0   \n",
       " 2019-11-11-16-08-04-450565_+2.27_-4.01_+43.00_+...                 0   \n",
       " \n",
       "                                                     label_proc_aged  \\\n",
       " 2019-11-11-18-45-13-933153_+2.33_+3.65_+72.70_+...                0   \n",
       " 2019-11-11-18-15-16-181618_+3.86_-5.25_+62.10_+...                0   \n",
       " 2019-11-11-17-26-44-366119_-1.57_-1.58_+82.70_+...                1   \n",
       " 2019-11-11-18-49-39-136200_-0.53_+4.32_+42.00_+...                0   \n",
       " 2019-11-11-18-33-59-261512_+5.11_+2.22_+27.00_+...                1   \n",
       " ...                                                             ...   \n",
       " 2019-11-11-18-39-00-862256_+6.58_-5.98_+80.50_+...                0   \n",
       " 2019-11-11-18-25-15-378611_+4.02_+6.50_+55.50_+...                0   \n",
       " 2019-11-11-17-00-10-687106_+2.27_+6.26_+55.40_+...                1   \n",
       " 2019-11-11-16-27-51-150735_-4.56_+3.79_+86.50_+...                0   \n",
       " 2019-11-11-16-08-04-450565_+2.27_-4.01_+43.00_+...                1   \n",
       " \n",
       "                                                     label_proc_frozen  \n",
       " 2019-11-11-18-45-13-933153_+2.33_+3.65_+72.70_+...                  0  \n",
       " 2019-11-11-18-15-16-181618_+3.86_-5.25_+62.10_+...                  0  \n",
       " 2019-11-11-17-26-44-366119_-1.57_-1.58_+82.70_+...                  0  \n",
       " 2019-11-11-18-49-39-136200_-0.53_+4.32_+42.00_+...                  0  \n",
       " 2019-11-11-18-33-59-261512_+5.11_+2.22_+27.00_+...                  0  \n",
       " ...                                                               ...  \n",
       " 2019-11-11-18-39-00-862256_+6.58_-5.98_+80.50_+...                  0  \n",
       " 2019-11-11-18-25-15-378611_+4.02_+6.50_+55.50_+...                  0  \n",
       " 2019-11-11-17-00-10-687106_+2.27_+6.26_+55.40_+...                  0  \n",
       " 2019-11-11-16-27-51-150735_-4.56_+3.79_+86.50_+...                  0  \n",
       " 2019-11-11-16-08-04-450565_+2.27_-4.01_+43.00_+...                  0  \n",
       " \n",
       " [2355 rows x 10 columns])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data():\n",
    "    print(\"Load data\")\n",
    "    data = pd.read_pickle(\"../data/train/train_set_128px.pkl\")\n",
    "    # use k fold cross validation later :)\n",
    "    data = data.loc[data['label_habit'] == \"Column\"]\n",
    "    train_data, val_data = train_test_split(data, stratify=data[\"label_proc_rimed\"], test_size=0.25, random_state=7655)\n",
    "    del data\n",
    "    #print(val_data.head(2))\n",
    "    return train_data, val_data\n",
    "#load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_sample(X_train, Y_train):\n",
    "    n_tot = len(Y_train)\n",
    "    n_pos = np.sum(Y_train)\n",
    "    n_neg = n_tot - n_pos\n",
    "    print(n_tot, n_pos, n_neg)\n",
    "    print(n_neg/(n_neg-n_pos))\n",
    "    \n",
    "    # Undersample Data -> Balance it\n",
    "    neg_idx = np.where(Y_train==0)[:]\n",
    "    idx_del = np.random.choice(n_neg, size=n_neg-n_pos, replace=False)\n",
    "    Y_train = np.delete(Y_train, neg_idx[idx_del])\n",
    "    X_train = np.delete(X_train, neg_idx[idx_del], axis=0)\n",
    "    return X_train, Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform to mean = 0, std = 1\n",
    "def standardize(images):\n",
    "    mean = images.mean(axis=(1,2), keepdims=True)\n",
    "    std = images.std(axis=(1,2), keepdims=True)\n",
    "    images = (images - mean) / std\n",
    "    return images\n",
    "\n",
    "# transform into range [0,1]\n",
    "def normalize1(images):\n",
    "    minimum = np.min(images, axis=(1,2), keepdims=True)\n",
    "    maximum = np.max(images, axis=(1,2), keepdims=True)\n",
    "    return (images - minimum) / (maximum-minimum)\n",
    "\n",
    "# transform into range [-1,1]\n",
    "def normalize2(images):\n",
    "    return (2*normalize1(images))-1\n",
    "\n",
    "# transform like in https://towardsdatascience.com/data-preprocessing-and-network-building-in-cnn-15624ef3a28b -> Normalization\n",
    "def normalize3(images):\n",
    "    minimum = np.min(images, axis=(1,2), keepdims=True)\n",
    "    maximum = np.max(images, axis=(1,2), keepdims=True)\n",
    "    return images - (minimum / maximum) - minimum\n",
    "\n",
    "def centering(images):\n",
    "    mean = np.mean(images, axis=(1,2), keepdims=True)\n",
    "    return normalize1(images-mean)\n",
    "\n",
    "def normalize_and_standardize(images):\n",
    "    images = normalize2(images)\n",
    "    mean = np.mean(images)\n",
    "    std = np.std(images)\n",
    "    images = (images - mean) / std\n",
    "    return images\n",
    "\n",
    "def preprocess_data2(train_data, val_data, run):\n",
    "    print(\"Preprocess data for 2 channels\", end=\" \")\n",
    "    \n",
    "    X_abs_train = run[\"normalize\"](np.stack(train_data[\"img_abs\"]))\n",
    "    X_ang_train = run[\"normalize\"](np.stack(train_data[\"img_ang\"]))\n",
    "    X_train = np.stack((X_abs_train, X_ang_train), axis=-1)\n",
    "    Y_train = train_data[run[\"label\"]].to_numpy()\n",
    "    del X_abs_train, X_ang_train\n",
    "    print(\"a\", end=\" \")\n",
    "    X_abs_val = run[\"normalize\"](np.stack(val_data[\"img_abs\"]))\n",
    "    X_ang_val = run[\"normalize\"](np.stack(val_data[\"img_ang\"]))\n",
    "    X_val = np.stack((X_abs_val, X_ang_val), axis=-1)\n",
    "    Y_val = val_data[run[\"label\"]].to_numpy()\n",
    "    del X_abs_val, X_ang_val\n",
    "    print(\"b\", end=\" \")\n",
    "    \n",
    "    if run[\"balance_dataset\"] == \"down_sampling\":\n",
    "        X_train, Y_train = down_sample(X_train, Y_train)    \n",
    "    elif run[\"balance_dataset\"] == \"up_sampling\":\n",
    "        print(\"up_sampling not yet implemented\")\n",
    "        return\n",
    "    \n",
    "    train_batches = (\n",
    "        tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "        .cache()\n",
    "        .shuffle(run[\"BUFFER_SIZE\"])\n",
    "        .batch(run[\"BATCH_SIZE\"])\n",
    "        #.repeat()\n",
    "        #.map(Augment())\n",
    "        .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    )\n",
    "    print(\"c\", end=\" \")\n",
    "    val_batches = (\n",
    "        tf.data.Dataset.from_tensor_slices((X_val, Y_val))\n",
    "        .cache()\n",
    "        .batch(run[\"BATCH_SIZE\"])\n",
    "        .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    )\n",
    "    del X_val, X_train\n",
    "    print(\"d\")\n",
    "    return train_batches, val_batches, Y_train, Y_val\n",
    "\n",
    "def preprocess_data3(train_data, val_data, run):\n",
    "    print(\"Preprocess data for 3 channels\", end=\" \")\n",
    "    \n",
    "    X_abs_train = run[\"normalize\"](np.stack(train_data[\"img_abs\"]))\n",
    "    X_ang_train = run[\"normalize\"](np.stack(train_data[\"img_ang\"]))\n",
    "    X_train = np.stack((X_abs_train, X_abs_train, X_ang_train), axis=-1)\n",
    "    Y_train = train_data[run[\"label\"]].to_numpy()\n",
    "    del X_abs_train, X_ang_train, train_data\n",
    "    print(\"a\", end=\" \")\n",
    "    \n",
    "    n_tot = len(Y_train)\n",
    "    n_pos = np.sum(Y_train)\n",
    "    n_neg = n_tot - n_pos\n",
    "    print(n_pos / n_tot, n_neg/n_tot)\n",
    "    \n",
    "    X_abs_val = run[\"normalize\"](np.stack(val_data[\"img_abs\"]))\n",
    "    X_ang_val = run[\"normalize\"](np.stack(val_data[\"img_ang\"]))\n",
    "    X_val = np.stack((X_abs_val, X_abs_val, X_ang_val), axis=-1)\n",
    "    Y_val = val_data[run[\"label\"]].to_numpy()\n",
    "    del X_abs_val, X_ang_val, val_data\n",
    "    print(\"b\", end=\" \")\n",
    "    \n",
    "    if run[\"balance_dataset\"] == \"down_sampling\":\n",
    "        X_train, Y_train = down_sample(X_train, Y_train)    \n",
    "    elif run[\"balance_dataset\"] == \"up_sampling\":\n",
    "        print(\"up_sampling not yet implemented\")\n",
    "        return\n",
    "    \n",
    "    train_batches = (\n",
    "        tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "        .cache()\n",
    "        .shuffle(run[\"BUFFER_SIZE\"])\n",
    "        .batch(run[\"BATCH_SIZE\"])\n",
    "        #.repeat()\n",
    "        #.map(Augment())\n",
    "        .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    )\n",
    "    print(\"c\", end=\" \")\n",
    "    val_batches = (\n",
    "        tf.data.Dataset.from_tensor_slices((X_val, Y_val))\n",
    "        .cache()\n",
    "        .batch(run[\"BATCH_SIZE\"])\n",
    "        .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    )\n",
    "    del X_val, X_train\n",
    "    print(\"d\")\n",
    "    return train_batches, val_batches, Y_train, Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModelDenseNet121(run):\n",
    "    IMG_SHAPE = (128, 128, 3)\n",
    "    if run[\"pretrained\"]:\n",
    "        pretrained_weights = 'imagenet'\n",
    "    else:\n",
    "        pretrained_weights = None\n",
    "    base_model = tf.keras.applications.densenet.DenseNet121(\n",
    "        include_top=False, weights=pretrained_weights,\n",
    "        input_shape=IMG_SHAPE, pooling='max')\n",
    "    \n",
    "    if run[\"pretrained\"]:\n",
    "        base_model.trainable = False\n",
    "    \n",
    "    #base_model.summary()\n",
    "    \n",
    "    inputs = tf.keras.Input(shape=(128,128,3))\n",
    "    x = tf.keras.layers.RandomFlip(mode=\"horizontal_and_vertical\")(inputs)\n",
    "    x = base_model(x, training=False)\n",
    "    x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model, base_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModelDenseNet121_noHead(run):\n",
    "    IMG_SHAPE = (128, 128, 3)\n",
    "    if run[\"pretrained\"]:\n",
    "        pretrained_weights = 'imagenet'\n",
    "    else:\n",
    "        pretrained_weights = None\n",
    "    base_model = tf.keras.applications.densenet.DenseNet121(\n",
    "        include_top=False, weights=pretrained_weights,\n",
    "        input_shape=IMG_SHAPE, pooling='max')\n",
    "    \n",
    "    base_model.trainable = True\n",
    "    \n",
    "    #base_model.summary()\n",
    "    \n",
    "    inputs = tf.keras.Input(shape=(128,128,3))\n",
    "    x = tf.keras.layers.RandomFlip(mode=\"horizontal_and_vertical\")(inputs)\n",
    "    x = base_model(x, training=True)\n",
    "    outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model, base_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModelDenseNet201(run):\n",
    "    IMG_SHAPE = (128, 128, 3)\n",
    "    if run[\"pretrained\"]:\n",
    "        pretrained_weights = 'imagenet'\n",
    "    else:\n",
    "        pretrained_weights = None\n",
    "    base_model = tf.keras.applications.densenet.DenseNet201(\n",
    "        include_top=False, weights=pretrained_weights,\n",
    "        input_shape=IMG_SHAPE, pooling='max')\n",
    "    \n",
    "    if run[\"pretrained\"]:\n",
    "        base_model.trainable = False\n",
    "    \n",
    "    #base_model.summary()\n",
    "    \n",
    "    inputs = tf.keras.Input(shape=(128,128,3))\n",
    "    #x = tf.keras.layers.RandomFlip(mode=\"horizontal_and_vertical\")(inputs)\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero-center each color channel with respect to the ImageNet dataset, without scaling.\n",
    "def getModelResNet50(run):\n",
    "    IMG_SHAPE = (128, 128, 3)\n",
    "    if run[\"pretrained\"]:\n",
    "        pretrained_weights = 'imagenet'\n",
    "    else:\n",
    "        pretrained_weights = None\n",
    "    base_model = tf.keras.applications.ResNet50(\n",
    "        include_top=False, weights=pretrained_weights,\n",
    "        input_shape=IMG_SHAPE, pooling='max')\n",
    "    \n",
    "    if run[\"pretrained\"]:\n",
    "        base_model.trainable = False\n",
    "    \n",
    "    #base_model.summary()\n",
    "    \n",
    "    inputs = tf.keras.Input(shape=(128,128,3))\n",
    "    #x = tf.keras.layers.RandomFlip(mode=\"horizontal_and_vertical\")(inputs)\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero-center each color channel with respect to the ImageNet dataset, without scaling.\n",
    "def getModelResNet152(run):\n",
    "    IMG_SHAPE = (128, 128, 3)\n",
    "    if run[\"pretrained\"]:\n",
    "        pretrained_weights = 'imagenet'\n",
    "    else:\n",
    "        pretrained_weights = None\n",
    "    base_model = tf.keras.applications.ResNet152(\n",
    "        include_top=False, weights=pretrained_weights,\n",
    "        input_shape=IMG_SHAPE, pooling='max')\n",
    "    \n",
    "    if run[\"pretrained\"]:\n",
    "        base_model.trainable = False\n",
    "    \n",
    "    #base_model.summary()\n",
    "    \n",
    "    inputs = tf.keras.Input(shape=(128,128,3))\n",
    "    #x = tf.keras.layers.RandomFlip(mode=\"horizontal_and_vertical\")(inputs)\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModelMobileNetV2(run):\n",
    "    IMG_SHAPE = (128, 128, 3)\n",
    "    if run[\"pretrained\"]:\n",
    "        pretrained_weights = 'imagenet'\n",
    "    else:\n",
    "        pretrained_weights = None\n",
    "    base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights=pretrained_weights, pooling='max')\n",
    "    if run[\"pretrained\"] and run[\"freeze_basemodel\"] == \"whole\":\n",
    "        base_model.trainable = False\n",
    "    #base_model.summary()\n",
    "    \n",
    "    inputs = tf.keras.Input(shape=(128,128,3))\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModelMobileNetV2_nohead(run):\n",
    "    IMG_SHAPE = (128, 128, 3)\n",
    "    if run[\"pretrained\"]:\n",
    "        pretrained_weights = 'imagenet'\n",
    "    else:\n",
    "        pretrained_weights = None\n",
    "    base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights=pretrained_weights, pooling='max')\n",
    "    \n",
    "    inputs = tf.keras.Input(shape=(128,128,3))\n",
    "    x = base_model(inputs, training=True)\n",
    "    outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(run):\n",
    "    initial_bias = run[\"initial_bias\"]\n",
    "    if initial_bias:\n",
    "        initial_bias = np.log([642/3551])\n",
    "    print(\"Make model\",initial_bias)\n",
    "\n",
    "    model, base_model = run[\"model\"](run)\n",
    "    model.summary()\n",
    "    \n",
    "    model.compile(optimizer = run[\"optimizer\"](learning_rate=run[\"learning_rate\"]),\n",
    "                  loss = run[\"loss\"],\n",
    "                  metrics = ['binary_accuracy',\n",
    "                             'hinge',\n",
    "                             tf.keras.metrics.AUC(name='auc'),\n",
    "                             tf.keras.metrics.Recall(name='recall'),\n",
    "                             tf.keras.metrics.Precision(name='precision')]\n",
    "             )\n",
    "    return model, base_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights(image, label):\n",
    "    #true_frac = 0.14963822851236383\n",
    "    #weights = tf.constant([true_frac, 1.0 - true_frac])\n",
    "    #weights = tf.constant([5.68 / 6.68, 1.0 / 6.68]) \n",
    "    weights = tf.constant([0.16299749633082966, 0.83700250366917])\n",
    "    sample_weights = tf.gather(weights, indices=tf.cast(label, tf.int64))\n",
    "    return image, label, sample_weights\n",
    "\n",
    "def train_model(model, train_batches, val_batches, run):\n",
    "    print(\"Train\")\n",
    "    #if run[\"weight\"]:\n",
    "    #    history = model.fit(train_batches.map(weights), epochs=run[\"epochs\"], \n",
    "    #                validation_data=val_batches, verbose=run[\"verbose\"])\n",
    "    #else:\n",
    "    \n",
    "    if run[\"early_stopping\"]:\n",
    "        callback = tf.keras.callbacks.EarlyStopping(monitor='val_binary_accuracy', patience=3, verbose=1,restore_best_weights=True)\n",
    "        history = model.fit(train_batches, epochs=run[\"epochs\"], \n",
    "                    validation_data=val_batches, verbose=run[\"verbose\"], callbacks=[callback])\n",
    "    else:\n",
    "        history = model.fit(train_batches, epochs=run[\"epochs\"], \n",
    "                        validation_data=val_batches, verbose=run[\"verbose\"])\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(history,Y_pred_prob, Y_val):\n",
    "    plt.plot(history.history['binary_accuracy'])\n",
    "    plt.plot(history.history['val_binary_accuracy'])\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.plot(history.history['hinge'])\n",
    "    plt.plot(history.history['val_hinge'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['accuracy', 'val_accuracy', 'loss', 'val_loss', 'hinge', 'val_hinge'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_raw_metrics(history,Y_pred_prob, Y_val):\n",
    "    prec = np.array(history.history['precision'])\n",
    "    rec = np.array(history.history['recall'])\n",
    "    val_prec = np.array(history.history['val_precision'])\n",
    "    val_rec = np.array(history.history['val_recall'])\n",
    "\n",
    "    # avoid division by zero\n",
    "    tol = 10e-7   \n",
    "    summe = prec + rec\n",
    "    val_summe = val_prec + val_rec\n",
    "    \n",
    "    summe = np.where(summe == 0.0, tol, summe)\n",
    "    val_summe = np.where(val_summe == 0.0, tol, val_summe)\n",
    "    \n",
    "    f1 = 2 * (prec * rec) / summe\n",
    "    val_f1 = 2 * (val_prec * val_rec) / val_summe\n",
    "    \n",
    "    plt.plot(history.history['recall'])\n",
    "    plt.plot(history.history['val_recall'])\n",
    "    plt.plot(history.history['precision'])\n",
    "    plt.plot(history.history['val_precision'])\n",
    "    plt.plot(f1)\n",
    "    plt.plot(val_f1)\n",
    " \n",
    "    plt.title('Recall & Precision')\n",
    "    plt.ylabel('rate')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['recall', 'val_recall', 'precision', 'val_precision', 'f1', 'val_f1'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ROC(history,Y_pred_prob, Y_val):\n",
    "    fpr, tpr, threshold = metrics.roc_curve(Y_val, Y_pred_prob)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    \n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "    print(\"AUC = \"+ str(roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all(history,Y_pred_prob, Y_val):\n",
    "    plot_metrics(history,Y_pred_prob, Y_val)\n",
    "    plot_raw_metrics(history,Y_pred_prob, Y_val)\n",
    "    plot_ROC(history,Y_pred_prob, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, val_batches, run):\n",
    "    print(\"Make predictions\")\n",
    "    Y_pred_prob = model.predict(val_batches)\n",
    "    print(Y_pred_prob.shape)\n",
    "    # TODO: change np where !\n",
    "    Y_pred = np.argmax(Y_pred_prob, axis=1)\n",
    "    #Y_pred = np.where(Y_pred_prob < 0.5, 0, 1)[0]\n",
    "    print(\"###############\", Y_pred.shape)\n",
    "    print(Y_pred)\n",
    "    return Y_pred, Y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print evaluate and save evaluation and run in a logfile\n",
    "def evaluate_model(y_true, y_pred, y_pred_prob, history, val_batches, run):\n",
    "    #model_summary = history.model.summary()\n",
    "    params = history.params\n",
    "    datestr = time.strftime(\"%y:%m:%d\")\n",
    "    timestr = time.strftime(\"%H:%M:%S\")\n",
    "    conf_mat = confusion_matrix(y_true, y_pred)\n",
    "    conf_mat_percent = 100 * conf_mat / len(y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='binary')\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    bce = log_loss(y_true, y_pred)\n",
    "    print(run[\"epochs\"])\n",
    "    print(conf_mat)\n",
    "    print(conf_mat_percent)\n",
    "    print(\"F1: \",f1)\n",
    "    print(\"Accuracy: \",acc)\n",
    "    print(\"Binary Cross Entropy: \", bce)\n",
    "    \n",
    "    if run[\"save\"]:       \n",
    "        filename = \"../logs/\"+datestr+\"/\"+timestr+\"_\"+run[\"label\"]+\"_\"+str(run[\"epochs\"])+\".txt\"\n",
    "        # make folder if it doesn't exist already\n",
    "        os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "        \n",
    "        f = open(filename, \"x\")\n",
    "        # write run specification\n",
    "        f.write(\"Label: \"+run[\"label\"]+\"\\n\")\n",
    "        f.write(\"Normalization: \"+run[\"normalize\"].__name__+\"\\n\")\n",
    "        f.write(\"Batch Size: \"+str(run[\"BATCH_SIZE\"])+\"\\n\")\n",
    "        f.write(\"Buffer Size: \"+str(run[\"BUFFER_SIZE\"])+\"\\n\")\n",
    "        f.write(\"Model Name: \"+run[\"model\"].__name__+\"\\n\")\n",
    "        f.write(\"Optimizer: \"+str(run[\"optimizer\"])+\"\\n\")\n",
    "        f.write(\"Loss: \"+str(run[\"loss\"])+\"\\n\")\n",
    "        f.write(\"Epochs: \"+str(run[\"epochs\"])+\"\\n\")\n",
    "        f.write(\"\\n\\n\")\n",
    "        \n",
    "        # write evaluation\n",
    "        f.write(\"F1: \"+str(f1)+\"\\n\")\n",
    "        f.write(\"Accuracy: \"+str(acc)+\"\\n\")\n",
    "        f.write(\"Logloss: \"+str(bce)+\"\\n\\n\")\n",
    "        \n",
    "        f.write(str(conf_mat)+\"\\n\\n\")\n",
    "        f.write(str(conf_mat_percent)+\"\\n\\n\")\n",
    "        \n",
    "        # write model summary\n",
    "        f.write(str(history.params) + \"\\n\\n\")\n",
    "        #f.write(str(model_summary))\n",
    "        history.model.summary(print_fn=lambda x: f.write(x + \"\\n\"))\n",
    "        f.close()\n",
    "        \n",
    "        # Get the dictionary containing each metric and the loss for each epoch\n",
    "        history_filename = \"../logs/history/\"+datestr+\"/\"+timestr+\"_\"+run[\"label\"]+\"_\"+str(run[\"epochs\"])+\".txt\"\n",
    "        os.makedirs(os.path.dirname(history_filename), exist_ok=True)\n",
    "        history_dict = history.history\n",
    "        json.dump(history_dict, open(history_filename, 'w'))\n",
    "    \n",
    "    find_misclassified(y_true, y_pred, y_pred_prob, val_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_misclassified(y_true, y_pred, y_pred_prob, val_batches):\n",
    "    print(y_true.shape, y_pred.shape)\n",
    "    wrong = np.square(y_true-y_pred) # 0 if true, 1 if false\n",
    "    print(\"wrongshape: \", wrong.shape)\n",
    "    print(\"wrong: \", wrong)\n",
    "    indices_wrong = np.where(wrong == 1)            \n",
    "    print(\"indices wrong\", indices_wrong)\n",
    "    \n",
    "    #labels = np.concatenate([label for img, label in val_batches], axis=0)\n",
    "    #images = np.concatenate([img for img, label in val_batches], axis=0)\n",
    "    #wrong_labels = labels[indices_wrong]\n",
    "    #wrong_images = images[indices_wrong]\n",
    "    \n",
    "    _, val_data = load_data()\n",
    "    \n",
    "    wrong_data = val_data.iloc(indices_wrong)\n",
    "    \n",
    "    basic_habit_dict = { \n",
    "        \"Column\": 0,\n",
    "        \"Plate\": 0,\n",
    "        \"Droplet\": 0,\n",
    "        \"Lollipop\": 0,\n",
    "        \"Irregular\": 0,\n",
    "        \"Small\": 0,\n",
    "        \"Plate Column\": 0\n",
    "    }\n",
    "    \n",
    "    for basic_habit in wrong_data[basic_habit]:\n",
    "        basic_habit_dict[basic_habit] += 1\n",
    "    \n",
    "    print(basic_habit_dict)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # find out how many particles belong to what class\n",
    "    \n",
    "    # find out size of particles\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_bias(y):\n",
    "    pos = np.sum(y)\n",
    "    neg = np.sum(1-y)\n",
    "    initial_bias = np.log([pos/neg])\n",
    "    return initial_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(run, continue_training=False):\n",
    "    if run[\"verbose\"]:\n",
    "        print(run)\n",
    "        \n",
    "    # start new model\n",
    "    if not continue_training:\n",
    "        train_data, val_data = load_data()    \n",
    "        train_batches, val_batches, Y_train, Y_val = run[\"preprocessing\"](train_data, val_data, run)\n",
    "        del train_data, val_data\n",
    "        if run[\"initial_bias\"]:\n",
    "            run[\"initial_bias\"] = initial_bias(Y_train)\n",
    "        del Y_train\n",
    "        model, base_model = make_model(run)\n",
    "        epochs_already_done = 0\n",
    "    \n",
    "    #continue training    \n",
    "    else:\n",
    "        run[\"initial_bias\"] = False\n",
    "        train_batches, val_batches, Y_val, model, old_history = continue_training\n",
    "        epochs_already_done = old_history.params[\"epochs\"]\n",
    "        \n",
    "    history = train_model(model, train_batches, val_batches, run)    \n",
    "    Y_pred, Y_pred_prob = predict(model, val_batches, run)\n",
    "    run[\"plot\"](history,Y_pred_prob, Y_val)\n",
    "    \n",
    "    run[\"epochs\"] += epochs_already_done\n",
    "    evaluate_model(Y_val, Y_pred, Y_pred_prob, history, val_batches, run)\n",
    "    return train_batches, val_batches, Y_val, model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment_finetune(run, continue_training=False):\n",
    "    if run[\"verbose\"]:\n",
    "        print(run)\n",
    "        \n",
    "    # start new model\n",
    "    if not continue_training:\n",
    "        train_data, val_data = load_data()    \n",
    "        train_batches, val_batches, Y_train, Y_val = run[\"preprocessing\"](train_data, val_data, run)\n",
    "        del train_data, val_data\n",
    "        if run[\"initial_bias\"]:\n",
    "            run[\"initial_bias\"] = initial_bias(Y_train)\n",
    "        del Y_train\n",
    "        model, base_model = make_model(run)\n",
    "        epochs_already_done = 0\n",
    "    \n",
    "    #continue training    \n",
    "    else:\n",
    "        run[\"initial_bias\"] = False\n",
    "        train_batches, val_batches, Y_val, model, old_history = continue_training\n",
    "        epochs_already_done = old_history.params[\"epochs\"]\n",
    "        \n",
    "    history = train_model(model, train_batches, val_batches, run)    \n",
    "    Y_pred, Y_pred_prob = predict(model, val_batches, run)\n",
    "    run[\"plot\"](history,Y_pred_prob, Y_val)\n",
    "    \n",
    "    run[\"epochs\"] += epochs_already_done\n",
    "    evaluate_model(Y_val, Y_pred, Y_pred_prob, history, run)\n",
    "    \n",
    "    base_model.trainable = True\n",
    "    # Let's take a look to see how many layers are in the base model\n",
    "    print(\"Number of layers in the base model: \", len(base_model.layers))\n",
    "\n",
    "    # Fine-tune from this layer onwards\n",
    "    fine_tune_at = 100\n",
    "\n",
    "    # Freeze all the layers before the `fine_tune_at` layer\n",
    "    for layer in base_model.layers[:fine_tune_at]:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    model.compile(optimizer = run[\"optimizer\"](learning_rate=run[\"learning_rate\"]/10),\n",
    "                  loss = run[\"loss\"],\n",
    "                  metrics = ['binary_accuracy',\n",
    "                             'hinge',\n",
    "                             tf.keras.metrics.AUC(name='auc'),\n",
    "                             tf.keras.metrics.Recall(name='recall'),\n",
    "                             tf.keras.metrics.Precision(name='precision')]\n",
    "             )\n",
    "    model.summary()\n",
    "    \n",
    "    fine_tune_epochs = 50\n",
    "    total_epochs = fine_tune_epochs + run[\"epochs\"]\n",
    "    \n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_binary_accuracy', patience=3, verbose=1,restore_best_weights=False)\n",
    "    history_fine = model.fit(train_batches, epochs=total_epochs, \n",
    "                    validation_data=val_batches, verbose=run[\"verbose\"], callbacks=[callback],\n",
    "                            initial_epoch=history.epoch[-1])\n",
    "    \n",
    "    Y_pred, Y_pred_prob = predict(model, val_batches, run)\n",
    "    run[\"plot\"](history,Y_pred_prob, Y_val)\n",
    "    \n",
    "    run[\"epochs\"] += epochs_already_done\n",
    "    evaluate_model(Y_val, Y_pred, Y_pred_prob, history, run)\n",
    "    \n",
    "    return train_batches, val_batches, Y_val, model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all parameters for each try in this dict, log later together with results\n",
    "run = {\n",
    "    # general\n",
    "    \"save\": False,\n",
    "    \"verbose\": 1,\n",
    "    \"plot\": plot_all,\n",
    "    \n",
    "    # preprocessing\n",
    "    \"balance_dataset\": \"False\", #\"down_sampling\" for True\n",
    "    \"label\": \"label_proc_aggregate\",\n",
    "    \"normalize\": normalize1,\n",
    "    \"BATCH_SIZE\": 64,\n",
    "    \"BUFFER_SIZE\": 1024, # try bigger!\n",
    "    # preprocess_data2 for 2 channel images, preprocess_data3 for 3 channels (e.g. for pretrained CNN)\n",
    "    \"preprocessing\": preprocess_data3,\n",
    "\n",
    "    \n",
    "    # model compile\n",
    "    \"model\": getModelMobileNetV2,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"pretrained\": True,\n",
    "    \"optimizer\": tf.keras.optimizers.Adam,\n",
    "    \"loss\": \"binary_crossentropy\",\n",
    "    \"weight\": False,\n",
    "    \"initial_bias\": False,\n",
    "    \"early_stopping\": True,\n",
    "    \"freeze_basemodel\": True,\n",
    "    \n",
    "    # model fit\n",
    "    \"epochs\": 1   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'save': False, 'verbose': 1, 'plot': <function plot_all at 0x7fd195eb3af0>, 'balance_dataset': 'False', 'label': 'label_proc_aggregate', 'normalize': <function normalize1 at 0x7fd195633310>, 'BATCH_SIZE': 64, 'BUFFER_SIZE': 1024, 'preprocessing': <function preprocess_data3 at 0x7fd195633670>, 'model': <function getModelMobileNetV2 at 0x7fd195ce30d0>, 'learning_rate': 0.001, 'pretrained': True, 'optimizer': <class 'keras.optimizer_v2.adam.Adam'>, 'loss': 'binary_crossentropy', 'weight': False, 'initial_bias': False, 'early_stopping': True, 'freeze_basemodel': True, 'epochs': 1}\n",
      "Load data\n",
      "                                                       shape  size  \\\n",
      "2019-11-11-18-45-13-933153_+2.33_+3.65_+72.70_+...  (30, 35)    35   \n",
      "2019-11-11-18-15-16-181618_+3.86_-5.25_+62.10_+...  (62, 29)    62   \n",
      "\n",
      "                                                                                              img_abs  \\\n",
      "2019-11-11-18-45-13-933153_+2.33_+3.65_+72.70_+...  [[2.7054569e-20, 2.1304332e-18, 3.447854e-18, ...   \n",
      "2019-11-11-18-15-16-181618_+3.86_-5.25_+62.10_+...  [[3.740776e-26, -8.6513574e-14, -2.6216236e-14...   \n",
      "\n",
      "                                                                                              img_ang  \\\n",
      "2019-11-11-18-45-13-933153_+2.33_+3.65_+72.70_+...  [[-2.1548317e-19, -1.2919434e-20, 1.502107e-19...   \n",
      "2019-11-11-18-15-16-181618_+3.86_-5.25_+62.10_+...  [[3.7774554e-27, 9.6614924e-15, 2.927725e-15, ...   \n",
      "\n",
      "                                                   label_habit  \\\n",
      "2019-11-11-18-45-13-933153_+2.33_+3.65_+72.70_+...      Column   \n",
      "2019-11-11-18-15-16-181618_+3.86_-5.25_+62.10_+...      Column   \n",
      "\n",
      "                                                    label_proc_pristine  \\\n",
      "2019-11-11-18-45-13-933153_+2.33_+3.65_+72.70_+...                    1   \n",
      "2019-11-11-18-15-16-181618_+3.86_-5.25_+62.10_+...                    1   \n",
      "\n",
      "                                                    label_proc_aggregate  \\\n",
      "2019-11-11-18-45-13-933153_+2.33_+3.65_+72.70_+...                     0   \n",
      "2019-11-11-18-15-16-181618_+3.86_-5.25_+62.10_+...                     0   \n",
      "\n",
      "                                                    label_proc_rimed  \\\n",
      "2019-11-11-18-45-13-933153_+2.33_+3.65_+72.70_+...                 0   \n",
      "2019-11-11-18-15-16-181618_+3.86_-5.25_+62.10_+...                 0   \n",
      "\n",
      "                                                    label_proc_aged  \\\n",
      "2019-11-11-18-45-13-933153_+2.33_+3.65_+72.70_+...                0   \n",
      "2019-11-11-18-15-16-181618_+3.86_-5.25_+62.10_+...                0   \n",
      "\n",
      "                                                    label_proc_frozen  \n",
      "2019-11-11-18-45-13-933153_+2.33_+3.65_+72.70_+...                  0  \n",
      "2019-11-11-18-15-16-181618_+3.86_-5.25_+62.10_+...                  0  \n",
      "Preprocess data for 3 channels a 0.20002831257078144 0.7999716874292185\n",
      "b c "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-26 19:25:39.441810: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1388838912 exceeds 10% of free system memory.\n",
      "2022-01-26 19:25:40.103171: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 463011840 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d\n",
      "Make model False\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable Functional object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_206278/3976136333.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_206278/230373680.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(run, continue_training)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mrun\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"initial_bias\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_bias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mepochs_already_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_206278/350728352.py\u001b[0m in \u001b[0;36mmake_model\u001b[0;34m(run)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Make model\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minitial_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable Functional object"
     ]
    }
   ],
   "source": [
    "exp1 = run_experiment(run, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exp = run_experiment(run, False) # all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exp2 = run_experiment(run, False) # only column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del exp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exp3 = run_experiment(run, False) #only column, nohead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exp4 = run_experiment(run, False) # all data, nohead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del exp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exp5 = run_experiment(run, False) # all, nohead, weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
