{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import io\n",
    "from scipy import ndimage\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "seed = 7655\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_labels returns a split of the label around a '_'\n",
    "# eg. split_labels(abcd_efg_h) = abcd, efg_h\n",
    "# first return is a guaranteed to be a valid string, second return is -1 if there is no '_' present, else it is a valid string\n",
    "# eg. split_labels(abcdef) = abcdef, -1\n",
    "def split_labels(old_label):\n",
    "    i = old_label.find('_')\n",
    "    if i == -1:\n",
    "        return old_label, -1\n",
    "    else:\n",
    "        return old_label[:i], old_label[i+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discard anything not ice\n",
    "# enter basic habit as string\n",
    "# enter physical process as one hot encoding:\n",
    "# 0 -> pristine\n",
    "# 1 -> aggregate\n",
    "# 2 -> rimed\n",
    "# 3 -> aged\n",
    "# return as a list, empty list if not ice\n",
    "\n",
    "# Column\n",
    "# Plate\n",
    "# Droplet\n",
    "# Lollipop\n",
    "# Irregular\n",
    "# Small\n",
    "# Plate_column\n",
    "\n",
    "def encode_label(label):\n",
    "    basic_habit_dict = { \n",
    "        \"Column\": \"Column\",\n",
    "        \"column\": \"Column\",\n",
    "        \"Plate\": \"Plate\",\n",
    "        \"Plates\": \"Plate\",\n",
    "        \"Droplet\": \"Droplet\",\n",
    "        \"Droplets\": \"Droplet\",\n",
    "        \"Droplet Lollipop\": \"Lollipop\",\n",
    "        \"lollipop\": \"Lollipop\",\n",
    "        \"Irregular\": \"Irregular\",\n",
    "        \"Small\": \"Small\",\n",
    "        \"Plate Column\": \"Plate Column\",\n",
    "\n",
    "        \"Droplet Frozen\": \"NoClass\",\n",
    "        \n",
    "        \"Rosette\": \"NoClass\",\n",
    "        \"Dendrite\": \"NoClass\",\n",
    "        \"Graupel\": \"NoClass\",\n",
    "        \"Branch\": \"NoClass\",\n",
    "        \"Out\": \"NoClass\", # out of focus\n",
    "        \"Recirculation\": \"NoClass\",\n",
    "        \"Others\": \"NoClass\",\n",
    "    }\n",
    "    physical_process_dict = {\n",
    "        \"pristine\": 0,\n",
    "        \"aggregate\": 1,\n",
    "        \"Aggregate\": 1,\n",
    "        \"rimed\": 2,\n",
    "        \"aged\": 3,\n",
    "    }\n",
    "    \n",
    "    original_label = label # for debugging, delete later\n",
    "    #print(original_label)\n",
    "    label_list = []\n",
    "    particle_label, label = split_labels(label)\n",
    "    if particle_label != \"Ice\" or label == -1: # not Ice or no basic habit defined\n",
    "        return []\n",
    "    \n",
    "    habit_label, label = split_labels(label)\n",
    "    if habit_label not in basic_habit_dict:\n",
    "        print(habit_label, \"not in habit dictionary\", original_label)\n",
    "        return []\n",
    "    \n",
    "    if basic_habit_dict[habit_label] == \"NoClass\":\n",
    "        return []\n",
    "    \n",
    "    # extra clause because plate column are sometimes labeled as \"plates_columns\", and the _ causes a problem with the destinction between habit and process\n",
    "    if (habit_label == \"Plates\" or habit_label == \"plates\") and label[:6] == \"column\":\n",
    "        _, label = split_labels(label)\n",
    "        habit_label = \"Plate Column\"\n",
    "    # extra clause because Droplet lollipop column are sometimes labeled as \"Droplet_lollipop\", and the _ causes a problem with the destinction between habit and process\n",
    "    if (habit_label == \"Droplet\" or habit_label == \"Droplets\") and label[:8] == \"lollipop\":\n",
    "        _, label = split_labels(label)\n",
    "        habit_label = \"Droplet Lollipop\"\n",
    "    # extra clause because Droplet lollipop column are sometimes labeled as \"Droplet_lollipop\", and the _ causes a problem with the destinction between habit and process\n",
    "    if (habit_label == \"Droplet\" or habit_label == \"Droplets\") and label[:6] == \"frozen\":\n",
    "        return []\n",
    "    \n",
    "    physical_process_list = [0,0,0,0]\n",
    "    label_list.append(basic_habit_dict[habit_label])\n",
    "    if label == -1: # no physical process defined -> pristine\n",
    "        physical_process_list[0] = 1\n",
    "        label_list.append(physical_process_list)\n",
    "        return label_list\n",
    "    \n",
    "    process_label, label = split_labels(label)\n",
    "    if process_label not in physical_process_dict:\n",
    "        print(process_label, habit_label, \"not in physical process dictionary \", original_label)\n",
    "        return []  #empty list \n",
    "    \n",
    "    while label != -1:\n",
    "        physical_process_list[physical_process_dict[process_label]] = 1\n",
    "        process_label, label = split_labels(label)\n",
    "    physical_process_list[physical_process_dict[process_label]] = 1\n",
    "    \n",
    "    # perform some checks:\n",
    "    # at least one physical process is set ( if no process, then pristine should be set)\n",
    "    assert physical_process_list[0] or physical_process_list[1] or physical_process_list[2] or physical_process_list[3] or physical_process_list[4] or physical_process_list[5]\n",
    "    # either not pristine, or not any of the others\n",
    "    assert physical_process_list[0] == 0 or (not physical_process_list[1] and not physical_process_list[2] and not physical_process_list[3] and not physical_process_list[4] and not physical_process_list[5])\n",
    "    label_list.append(physical_process_list)\n",
    "    return label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(number_parts):\n",
    "    directory = os.getcwd()\n",
    "    file_paths = []\n",
    "    for i in range(number_parts):        \n",
    "        #file_paths.append(directory + \"/../data/huiying_labeled/uncropped_oldLabelling/huiying_uncropped_part\"+str(i+1)+\".mat\")\n",
    "        file_paths.append(directory + \"/../data/huiying_labeled/cropped_oldLabelling/huiying_part\"+str(i+1)+\".mat\")\n",
    "    \n",
    "    # load data like in holosuite/predict_pipeline/preprocessing.py\n",
    "    data_index = []\n",
    "    data_dict = {\"img\": [], \"label\":[]}\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        print(file_path)\n",
    "\n",
    "        var = io.whosmat(file_path)[0][0]\n",
    "        mat = io.loadmat(file_path, squeeze_me=True, struct_as_record=False)\n",
    "        ids = mat[var].prtclID\n",
    "        imgs = mat[var].prtclIm\n",
    "        labels = mat[var].cpType\n",
    "\n",
    "        for j, (id_, img, label) in enumerate(zip(ids, imgs, labels)):\n",
    "            # Check for missing IDs\n",
    "            if isinstance(id_, np.ndarray):\n",
    "                id_ = \"no_id_{}\".format(j + 1)\n",
    "                print(\"prtclID missing in row {}, substituting with '{}'\".format(j + 1, id_))\n",
    "            # Check for duplicate IDs\n",
    "            if id_ in data_index:\n",
    "                print(\"ID {} not unique\".format(id_))\n",
    "\n",
    "            label = encode_label(label)\n",
    "            if len(label) != 0:\n",
    "                data_index.append(id_)\n",
    "                data_dict[\"label\"].append(label)\n",
    "                data_dict[\"img\"].append(img)\n",
    "\n",
    "    dataset = pd.DataFrame(data_dict, index=data_index)\n",
    "    print(\"Done loading\")\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from holosuite/predict_pipeline/preprocessing.py\n",
    "# added a border of 10% of max(img.shape)\n",
    "def preprocess_img(img, img_size=-1):\n",
    "    \"\"\"Preprocess an image.\n",
    "    \n",
    "    The pixels of the image with NaN value are replaced with zeros. If `img_size` is not negative, the image is then\n",
    "    zero-padded to square shape and then scaled to `img_size`x`img_size`.\n",
    "    \n",
    "    Args:\n",
    "        img: An image array.\n",
    "        img_size: Dimensions of the output image (`img_size`x`img_size`), use -1 to keep the original dimensions.\n",
    "        \n",
    "    Returns:\n",
    "        The preprocessed image array.\n",
    "    \"\"\"\n",
    "    # Replace NaN entries with 0\n",
    "    img = np.nan_to_num(img)\n",
    "    if img_size < 0:\n",
    "        # Keep original size\n",
    "        prep_img = img\n",
    "    else:\n",
    "        # Pad and scale images\n",
    "        max_dim = max(img.shape)# + int(np.ceil(0.1*max(img.shape)))\n",
    "        pad_shape = (max_dim - img.shape[0], max_dim - img.shape[1])\n",
    "        pad_h_t = pad_shape[0]//2\n",
    "        pad_h_b = pad_shape[0]//2 + pad_shape[0]%2\n",
    "        pad_w_l = pad_shape[1]//2\n",
    "        pad_w_r = pad_shape[1]//2 + pad_shape[1]%2\n",
    "        square_img = np.pad(img, ((pad_h_t, pad_h_b), (pad_w_l, pad_w_r)), \"constant\", constant_values=0)\n",
    "        prep_img = ndimage.zoom(square_img, img_size/max_dim)\n",
    "    \n",
    "    return prep_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    img_size = 128\n",
    "    data[\"shape\"] = data[\"img\"].map(lambda img: img.shape)\n",
    "    data[\"size\"] = data[\"shape\"].map(lambda shape: max(shape))\n",
    "    data[\"img_abs\"] = data[\"img\"].map(lambda img: preprocess_img(np.absolute(img), img_size))\n",
    "    data[\"img_ang\"] = data[\"img\"].map(lambda img: preprocess_img(np.angle(img), img_size))\n",
    "    data[\"label_habit\"] = data[\"label\"].map(lambda label: label[0])\n",
    "    data[\"label_proc_pristine\"] = data[\"label\"].map(lambda label: label[1][0])\n",
    "    data[\"label_proc_aggregate\"] = data[\"label\"].map(lambda label: label[1][1])\n",
    "    data[\"label_proc_rimed\"] = data[\"label\"].map(lambda label: label[1][2])\n",
    "    data[\"label_proc_aged\"] = data[\"label\"].map(lambda label: label[1][3])\n",
    "    data = data.drop(columns=['label', 'img'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bkrumme/bachelors-thesis-bkrumme/source/../data/huiying_labeled/cropped_oldLabelling/huiying_part1.mat\n",
      "/home/bkrumme/bachelors-thesis-bkrumme/source/../data/huiying_labeled/cropped_oldLabelling/huiying_part2.mat\n",
      "/home/bkrumme/bachelors-thesis-bkrumme/source/../data/huiying_labeled/cropped_oldLabelling/huiying_part3.mat\n",
      "Done loading\n"
     ]
    }
   ],
   "source": [
    "# change image size in function preprocess data (now 128x128)\n",
    "data = preprocess_data(load_data(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, stratify=data[\"label_proc_rimed\"], test_size=0.2, random_state=636)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "label_proc_pristine     0.564491\n",
      "label_proc_aggregate    0.164206\n",
      "label_proc_rimed        0.107550\n",
      "label_proc_aged         0.220539\n",
      "dtype: float64\n",
      "\n",
      "Test:\n",
      "label_proc_pristine     0.569283\n",
      "label_proc_aggregate    0.160321\n",
      "label_proc_rimed        0.107485\n",
      "label_proc_aged         0.218078\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Print physical process distribution over test and train set\n",
    "print(\"Train:\")\n",
    "print(train[[\"label_proc_pristine\",\"label_proc_aggregate\",\"label_proc_rimed\",\"label_proc_aged\"]].mean())\n",
    "print(\"\\nTest:\")\n",
    "print(test[[\"label_proc_pristine\",\"label_proc_aggregate\",\"label_proc_rimed\",\"label_proc_aged\"]].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "[0.705 0.161 0.117 0.066 0.033 0.011]\n",
      "Test:\n",
      "[0.706 0.163 0.119 0.064 0.037 0.01 ]\n"
     ]
    }
   ],
   "source": [
    "# Print basic habit distribution over test and train set\n",
    "print(\"Train:\")\n",
    "habits_train = np.array(train['label_habit'].str.split(expand=True).stack().value_counts())\n",
    "n_train = len(train['label_habit'])\n",
    "print(np.around(habits_train/n_train, decimals=3))\n",
    "\n",
    "print(\"Test:\")\n",
    "habits_test = np.array(test['label_habit'].str.split(expand=True).stack().value_counts())\n",
    "n_test = len(test['label_habit'])\n",
    "print(np.around(habits_test/n_test, decimals=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as pickle\n",
    "#test.to_pickle(\"../data/test/uncropped_oldLabelling/test_set_128px.pkl\")\n",
    "#train.to_pickle(\"../data/train/uncropped_oldLabelling/train_set_128px.pkl\")\n",
    "test.to_pickle(\"../data/test/cropped_oldLabelling/test_set_128px.pkl\")\n",
    "train.to_pickle(\"../data/train/cropped_oldLabelling/train_set_128px.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
